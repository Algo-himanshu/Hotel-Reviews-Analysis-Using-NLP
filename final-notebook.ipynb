{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Notebook\n",
    "\n",
    "<b>Title:</b> Hotel Review Analysis Using NLP and Machine Learning\n",
    "\n",
    "<b>Author:</b> Ismael Araujo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "One of the biggest problems that many companies have been battleling is how to take advantage of all the data that is collected by them. The travel industry has been challenged by the amount of data. One of the types of data is reviews left by guests in websites such as Booking.com, TripAdvisor, and Yelp.\n",
    "\n",
    "Hotels have been trying to find ways to analyze the reviews and get insights out of it. However, some hotels can receive thousands of guests every week and hundreds of reviews. It becomes nearly impossible and expensive for hotels to keep track of the reviews. Thus, multiple hotels might negligete these valuable data due to the cost and energy that need to be allocated.\n",
    "\n",
    "For these reasons, here are a few questions that I will try to answer with this project:\n",
    "\n",
    "Can machine learning be used to correctly identify positive or negative reviews?\n",
    "Can NLP be used to create a useful word cloud with the the positive and negative reviews?\n",
    "How is a specific hotel compared to the other hotels in the same city? Can we find more information about the guests based on their review?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset for this project was originally used in the study Text Mining in Hotel Reviews: Impact of Words Restriction in Text Classification by Diego Campos, Rodrigo Rocha Silva, and Jorge Bernadino and a team at University of Coimbra. You can find the paper here. The raw dataset is from Kaggle. Since some datasets were large, you can download the cvs files here. The original dataset had 515,738 observations and 17 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T20:35:34.179475Z",
     "start_time": "2020-12-15T20:35:31.366039Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "\n",
    "# NLP Packages\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob \n",
    "from textblob import Word\n",
    "import re\n",
    "import string\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error, precision_score, f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ImbLearn Packages\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', 10000)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Solve warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T20:35:37.353230Z",
     "start_time": "2020-12-15T20:35:34.182086Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import csv file\n",
    "df = pd.read_csv('csv/Hotel_Reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T20:35:37.404753Z",
     "start_time": "2020-12-15T20:35:37.358701Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understand Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea in this step is to take a look at the data. A key points that I want to investigate are:\n",
    "- Shape of the dataset\n",
    "- If there are null values\n",
    "- How many unique hotels and if it matches to the value said in the dataset\n",
    "- The types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:00.536440Z",
     "start_time": "2020-12-11T19:38:00.533706Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Taking a lot at the dataset\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:01.733707Z",
     "start_time": "2020-12-11T19:38:01.723757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(515738, 17)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the shape of the dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:01.894657Z",
     "start_time": "2020-12-11T19:38:01.889706Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Address', 'Additional_Number_of_Scoring', 'Review_Date',\n",
       "       'Average_Score', 'Hotel_Name', 'Reviewer_Nationality',\n",
       "       'Negative_Review', 'Review_Total_Negative_Word_Counts',\n",
       "       'Total_Number_of_Reviews', 'Positive_Review',\n",
       "       'Review_Total_Positive_Word_Counts',\n",
       "       'Total_Number_of_Reviews_Reviewer_Has_Given', 'Reviewer_Score', 'Tags',\n",
       "       'days_since_review', 'lat', 'lng'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:02.650617Z",
     "start_time": "2020-12-11T19:38:02.593458Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting only the columns that I will use\n",
    "features = ['Hotel_Name', 'Negative_Review','Positive_Review', 'Reviewer_Score']\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:09.187653Z",
     "start_time": "2020-12-11T19:38:08.960172Z"
    }
   },
   "outputs": [],
   "source": [
    "df['Reviews'] = df['Negative_Review'] + df['Positive_Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:10.018869Z",
     "start_time": "2020-12-11T19:38:09.837761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reducing the size of the dataframe to 20%\n",
    "df = df.sample(frac=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:10.860602Z",
     "start_time": "2020-12-11T19:38:10.857187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103148, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if it worked\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:11.942848Z",
     "start_time": "2020-12-11T19:38:11.924874Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hotel_Name         0\n",
       "Negative_Review    0\n",
       "Positive_Review    0\n",
       "Reviewer_Score     0\n",
       "Reviews            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:13.146739Z",
     "start_time": "2020-12-11T19:38:13.140701Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how many hotels in this dataset\n",
    "len(df.Hotel_Name.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:14.231498Z",
     "start_time": "2020-12-11T19:38:14.220181Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hotel_Name\n",
       "Britannia International Hotel Canary Wharf           965\n",
       "Strand Palace Hotel                                  900\n",
       "Park Plaza Westminster Bridge London                 846\n",
       "Copthorne Tara Hotel London Kensington               748\n",
       "DoubleTree by Hilton Hotel London Tower of London    641\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the hotel with the highest number of reviews\n",
    "df.pivot_table(index=['Hotel_Name'], aggfunc='size').nlargest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings:\n",
    "\n",
    "- There are reviews from 1,492 hotels\n",
    "- The data is fairly clean. It doesn't much null values\n",
    "- It's missing the cities where the hotels are located.\n",
    "- There are reviews without the latitude and longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will start the data cleaning. I am expecting to do it in different steps depending on the complexity of the data. Since the main focus on this data set is to prepare data for the vanilla model, I won't overwork the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Punctuation and Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:19.459674Z",
     "start_time": "2020-12-11T19:38:19.456019Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score',\n",
       "       'Reviews'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:20.557766Z",
     "start_time": "2020-12-11T19:38:20.553225Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function lowercase all the review words, removes punctuation and numbers\n",
    "def clean_text_round1(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "round1 = lambda x: clean_text_round1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:22.605137Z",
     "start_time": "2020-12-11T19:38:21.533227Z"
    }
   },
   "outputs": [],
   "source": [
    "# Applying clean_text_round1 function\n",
    "df['Reviews_Clean'] = pd.DataFrame(df.Reviews.apply(round1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:43.522162Z",
     "start_time": "2020-12-11T19:38:43.510926Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Reviews_Clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356054</th>\n",
       "      <td>Canal House</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Nothing was too much trouble The staff were a...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No Negative Nothing was too much trouble The s...</td>\n",
       "      <td>no negative nothing was too much trouble the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395957</th>\n",
       "      <td>Grosvenor House A JW Marriott Hotel</td>\n",
       "      <td>I had a Junior suite The bed was only a queen...</td>\n",
       "      <td>I loved there shower It felt like you were un...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>I had a Junior suite The bed was only a queen...</td>\n",
       "      <td>i had a junior suite the bed was only a queen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468352</th>\n",
       "      <td>Imperial Riding School Renaissance Vienna Hotel</td>\n",
       "      <td>staff could be less rude the pool area is hor...</td>\n",
       "      <td>beds really comfy and the location is great a...</td>\n",
       "      <td>6.7</td>\n",
       "      <td>staff could be less rude the pool area is hor...</td>\n",
       "      <td>staff could be less rude the pool area is hor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281462</th>\n",
       "      <td>Hotel SB Icaria Barcelona</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Really nice hotel good facilities great staff...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>No Negative Really nice hotel good facilities ...</td>\n",
       "      <td>no negative really nice hotel good facilities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498978</th>\n",
       "      <td>Hotel Vilamar</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>Everything is super And room and design Very ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>No Negative Everything is super And room and d...</td>\n",
       "      <td>no negative everything is super and room and d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Hotel_Name  \\\n",
       "356054                                      Canal House   \n",
       "395957              Grosvenor House A JW Marriott Hotel   \n",
       "468352  Imperial Riding School Renaissance Vienna Hotel   \n",
       "281462                        Hotel SB Icaria Barcelona   \n",
       "498978                                   Hotel Vilamar    \n",
       "\n",
       "                                          Negative_Review  \\\n",
       "356054                                        No Negative   \n",
       "395957   I had a Junior suite The bed was only a queen...   \n",
       "468352   staff could be less rude the pool area is hor...   \n",
       "281462                                        No Negative   \n",
       "498978                                        No Negative   \n",
       "\n",
       "                                          Positive_Review  Reviewer_Score  \\\n",
       "356054   Nothing was too much trouble The staff were a...            10.0   \n",
       "395957   I loved there shower It felt like you were un...            10.0   \n",
       "468352   beds really comfy and the location is great a...             6.7   \n",
       "281462   Really nice hotel good facilities great staff...             9.6   \n",
       "498978   Everything is super And room and design Very ...            10.0   \n",
       "\n",
       "                                                  Reviews  \\\n",
       "356054  No Negative Nothing was too much trouble The s...   \n",
       "395957   I had a Junior suite The bed was only a queen...   \n",
       "468352   staff could be less rude the pool area is hor...   \n",
       "281462  No Negative Really nice hotel good facilities ...   \n",
       "498978  No Negative Everything is super And room and d...   \n",
       "\n",
       "                                            Reviews_Clean  \n",
       "356054  no negative nothing was too much trouble the s...  \n",
       "395957   i had a junior suite the bed was only a queen...  \n",
       "468352   staff could be less rude the pool area is hor...  \n",
       "281462  no negative really nice hotel good facilities ...  \n",
       "498978  no negative everything is super and room and d...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:38:54.356070Z",
     "start_time": "2020-12-11T19:38:54.346121Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# df['Reviews_Clean_2'] = df['Reviews_Clean'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:55:25.603110Z",
     "start_time": "2020-12-11T17:55:18.352627Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create a new column only with English words\n",
    "# words = set(nltk.corpus.words.words())\n",
    "# df['Negative_Review_Clean2'] = ''\n",
    "\n",
    "# for index in df.index:\n",
    "#     sent = df.Negative_Review_Clean[index]\n",
    "#     df['Negative_Review_Clean2'][index] = \" \".join(w for w in nltk.wordpunct_tokenize(sent) if w.lower() in words or not w.isalpha())\n",
    "    \n",
    "#     # 32 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Findings and Takeaways:\n",
    "\n",
    "- There are 17 hotels without latitude and longitude. I'll work on it as a stretch goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEED TO WORK ON THAT - Fix Spelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To do a spell check, I will choose a random review and check if there is any misspells in it\n",
    "- I will create a function that will use TextBlob to fix misspellings\n",
    "- Check the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-10T15:45:02.804933Z",
     "start_time": "2020-12-10T15:45:02.800864Z"
    }
   },
   "source": [
    "It seems that there are a few misspellings, such as the words `theough` and `extreamly`. I'll use TextBlob to fix them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:18:14.322049Z",
     "start_time": "2020-12-11T19:18:14.318786Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Create function to fix misspells\n",
    "# # Create a function to get subjectivity\n",
    "# def spellcheck(text):\n",
    "#     return Word(text).spellcheck\n",
    "\n",
    "# # def spellcheck(text):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:21:28.925877Z",
     "start_time": "2020-12-11T19:21:28.921869Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['Reviews_Clean'][356054]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:21:11.858349Z",
     "start_time": "2020-12-11T19:21:11.854232Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Checking if function works\n",
    "# spellcheck(df['Reviews_Clean'][356054])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:52:25.151194Z",
     "start_time": "2020-12-11T17:52:25.148457Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# w = Word(df['Negative_Review'][4])\n",
    "# w.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:52:25.496380Z",
     "start_time": "2020-12-11T17:52:25.493626Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['Negative_Review_SC'] = df['Negative_Review'].apply(spellcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:52:27.130884Z",
     "start_time": "2020-12-11T17:52:27.128390Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df.Negative_Review[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:52:27.797092Z",
     "start_time": "2020-12-11T17:52:27.794395Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# blob = TextBlob(df.Negative_Review[4])\n",
    "# blob.correct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings and Takeaways:\n",
    "- While checking a random "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, I will generate a sentiment analysis. Normally, this would be a step that I'd run after data cleaning for NLP. However, previous tests showed me that data cleaning does not affect the sentiment analysis using TextBlob.\n",
    "\n",
    "Running sentiment analysis takes a lot of time because I have more than 515K observations. For this reason, once the sentiment analysis is created, I will pickle the DataFrame and upload it again, so it won't run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:21:52.898457Z",
     "start_time": "2020-12-11T19:21:52.894868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a function to get subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "# Create a function to get polarity with tweets\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE:</b>\n",
    "\n",
    "Each of the two following cells takes around 10 minutes to run. For this reason, I will sabe the DataFrame into a csv file and upload it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:22:21.478650Z",
     "start_time": "2020-12-11T19:21:54.395981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create new columns to compare polarity and subjetivity on Negative Reviews\n",
    "df['Polarity_Net'] = df['Negative_Review'].apply(getPolarity)\n",
    "df['Polarity_Pos'] = df['Positive_Review'].apply(getPolarity)\n",
    "\n",
    "# 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-13T02:51:37.049403Z",
     "start_time": "2020-12-13T02:51:36.926827Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ac559b6f8e71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Saving csv with sentiment analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csv/df_sentiment_analysis.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Saving csv with sentiment analysis\n",
    "df.to_csv(\"csv/df_sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the Updated DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's import the DataFrame again with the sentiment analysis and check if the results make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:22:29.580848Z",
     "start_time": "2020-12-11T19:22:29.339304Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing DataFrame with new Polarity column\n",
    "df = pd.read_csv('csv/df_sentiment_analysis.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:22:30.699502Z",
     "start_time": "2020-12-11T19:22:30.694669Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score',\n",
       "       'Reviews', 'Reviews_Clean', 'Polarity_Net', 'Polarity_Pos'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:22:32.314807Z",
     "start_time": "2020-12-11T19:22:32.291586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating function to classify the Sentiment Analysis\n",
    "df['Sent_Analysis_Neg'] = df['Polarity_Net'].apply(lambda x: 0 if x < 0 else 1 if x > -0.1 and x < 0.1 else 2)\n",
    "df['Sent_Analysis_Pos'] = df['Polarity_Pos'].apply(lambda x: 0 if x < 0 else 1 if x > -0.1 and x < 0.1 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:22:33.513461Z",
     "start_time": "2020-12-11T19:22:33.506761Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a csv file with the sentiment analysis\n",
    "sentiment_analysis = df[['Hotel_Name','Negative_Review','Positive_Review','Reviewer_Score','Sent_Analysis_Neg','Sent_Analysis_Pos']]\n",
    "\n",
    "# Uncomment cell below to export file\n",
    "# sentiment_analysis.to_csv('sentiment_analysis.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings and Takeaways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It was created Subjectivity and Polarity features using sentiment analysis for Negative and Positive Reviews. \n",
    "- Polarity ranges between -1 and 1. Where -1 means that the review was very negative and 1 means that the review was very positive.\n",
    "- Seems like sentiment analysis does a good job identifying positive reviews, but the negative reviews could be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will create a target variable and use it to train my models. I will turn the Reviewer Score classes feature into:\n",
    "\n",
    "- <b>0 - Bad:</b> Scores below 5\n",
    "- <b>1 - Regular:</b> Scores between 5 and 7\n",
    "- <b>2 - Good:</b> Scores above 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:25:20.982811Z",
     "start_time": "2020-12-11T19:25:20.965108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create function that turns the Reviewer Score into a classification target with 3 values\n",
    "df['Score'] = df['Reviewer_Score'].apply(lambda x: 0 if x < 5 else 1 if x >= 5 and x < 7 else 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:25:22.955184Z",
     "start_time": "2020-12-11T19:25:22.944610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>356054</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395957</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468352</th>\n",
       "      <td>6.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281462</th>\n",
       "      <td>9.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498978</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Reviewer_Score  Score\n",
       "356054            10.0      2\n",
       "395957            10.0      2\n",
       "468352             6.7      1\n",
       "281462             9.6      2\n",
       "498978            10.0      2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if function worked\n",
    "df[['Reviewer_Score', 'Score']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:25:31.330545Z",
     "start_time": "2020-12-11T19:25:31.322536Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    85623\n",
       "1    13027\n",
       "0     4498\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there will be class imbalance\n",
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings and Takeways:\n",
    "- I created the target variable and turned it until numbers. 0 means that is a bad review. 1 means that is a neutral review, and 2 means that is a positive review. \n",
    "- There is a big class imbalance in this data set. It is taking a few seconds to process the data. I'll work on it in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving Class Imbalance Manually"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to start reducing the size of the set and fix the class imbalance manually. It will help to process the data faster. There are around 20 times more positive scores than negative scores; And around 30% more neutral scores than negative scores. To do so, I will:\n",
    "\n",
    "- Create different dataframes with for each class\n",
    "- Take a sample of each data frame accordingly to it's size\n",
    "    - 5% of the positive score\n",
    "    - 30% of the neutral score\n",
    "- The I will concatenate the results\n",
    "- Export the new dataset, so I can use it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:26:18.371117Z",
     "start_time": "2020-12-11T19:26:18.360055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating separate dataframes depending on the classification\n",
    "df_Score_0 = df[df.Score == 0]\n",
    "df_Score_1 = df[df.Score == 1].sample(frac=0.3)\n",
    "df_Score_2 = df[df.Score == 2].sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:26:19.180898Z",
     "start_time": "2020-12-11T19:26:19.169079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12687, 11)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating th \n",
    "df = pd.concat([df_Score_2, df_Score_1, df_Score_0])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:26:19.829712Z",
     "start_time": "2020-12-11T19:26:19.822678Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4498\n",
       "2    4281\n",
       "1    3908\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Score.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:24:46.783920Z",
     "start_time": "2020-12-11T17:24:45.187261Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving csv with sentiment analysis\n",
    "features = ['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score', 'Reviews_Clean', 'Score']\n",
    "df = df[features]\n",
    "df.to_csv(\"csv/df_no_class_imbalance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Findings and Takeaways:\n",
    "\n",
    "- There is class imbalance in the target variable. Since the dataset if very large, I manually downsampled the dataset to solve class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:27:34.777923Z",
     "start_time": "2020-12-11T17:27:34.198329Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Importing data set with the class imbalance fixed\n",
    "# df = pd.read_csv('csv/df_no_class_imbalance.csv', index_col=0)\n",
    "# features = ['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score', 'Reviews_Clean', 'Score']\n",
    "# df = df[features]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score',\n",
       "       'Reviews_Clean', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.col umns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T19:37:25.356356Z",
     "start_time": "2020-12-11T19:37:25.340565Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use English stemmer.\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# stemmer = SnowballStemmer(\"english\")\n",
    "# df['stemmed'] = df['unstemmed'].apply(lambda x: [stemmer.stem(y) for y in x])\n",
    "# df.drop(columns=(['unstemmed']), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use English lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before preparing the data for model sampling, I have two problems to solve:\n",
    "\n",
    "- <b>Class imbalance:</b> There is a big class imbalance in my data set, where there are more positive reviews than negative reviews.\n",
    "- <b>Curse of Dimensionality:</b> Since my dataset is so large, I'd end up with more than 50,000 features on top of 515K rows. That's too much for my computer to handle with.\n",
    "\n",
    "Luckily, I might be able to solve both problems at the same time. First, I will balance my target manually, which will help me solve the Curse of Dimensionality partially. Then, I will use Sparse on tokenized dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:42:58.479491Z",
     "start_time": "2020-12-11T17:42:58.473964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluation(y_true, y_pred):\n",
    "       \n",
    "# Print Accuracy, Recall, F1 Score, and Precision metrics.\n",
    "    print('Evaluation Metrics:')\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(y_test, y_pred)))\n",
    "    print('F1 Score: ' + str(metrics.f1_score(y_test, y_pred, average=\"weighted\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T18:57:04.243993Z",
     "start_time": "2020-12-11T18:57:04.239661Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Hotel_Name', 'Negative_Review', 'Positive_Review', 'Reviewer_Score',\n",
       "       'Reviews_Clean', 'Score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T18:57:12.104400Z",
     "start_time": "2020-12-11T18:57:12.075687Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Reviews_Clean</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>279305</th>\n",
       "      <td>Catalonia Atenas</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Staff nice location excellent breakfast amazi...</td>\n",
       "      <td>8.8</td>\n",
       "      <td>nothing staff nice location excellent breakfa...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330486</th>\n",
       "      <td>Avenida Palace</td>\n",
       "      <td>No bar or restaurant</td>\n",
       "      <td>No Positive</td>\n",
       "      <td>9.2</td>\n",
       "      <td>no bar or restaurant no positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223191</th>\n",
       "      <td>DoubleTree by Hilton London Islington</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>The very friendly and helpful staff Made us f...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>no negative the very friendly and helpful staf...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282475</th>\n",
       "      <td>Hotel Ronda Lesseps</td>\n",
       "      <td>Breakfast could have been better</td>\n",
       "      <td>Nice hotel super nice rooms and great locatio...</td>\n",
       "      <td>8.3</td>\n",
       "      <td>breakfast could have been better  nice hotel ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436370</th>\n",
       "      <td>Crowne Plaza London Docklands</td>\n",
       "      <td>Breakfast Staff not all really helpful a litt...</td>\n",
       "      <td>Location was great beautiful view close to Co...</td>\n",
       "      <td>7.9</td>\n",
       "      <td>breakfast staff not all really helpful a litt...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Hotel_Name  \\\n",
       "279305                       Catalonia Atenas   \n",
       "330486                         Avenida Palace   \n",
       "223191  DoubleTree by Hilton London Islington   \n",
       "282475                    Hotel Ronda Lesseps   \n",
       "436370          Crowne Plaza London Docklands   \n",
       "\n",
       "                                          Negative_Review  \\\n",
       "279305                                            Nothing   \n",
       "330486                              No bar or restaurant    \n",
       "223191                                        No Negative   \n",
       "282475                  Breakfast could have been better    \n",
       "436370   Breakfast Staff not all really helpful a litt...   \n",
       "\n",
       "                                          Positive_Review  Reviewer_Score  \\\n",
       "279305   Staff nice location excellent breakfast amazi...             8.8   \n",
       "330486                                        No Positive             9.2   \n",
       "223191   The very friendly and helpful staff Made us f...            10.0   \n",
       "282475   Nice hotel super nice rooms and great locatio...             8.3   \n",
       "436370   Location was great beautiful view close to Co...             7.9   \n",
       "\n",
       "                                            Reviews_Clean  Score  \n",
       "279305   nothing staff nice location excellent breakfa...      2  \n",
       "330486                   no bar or restaurant no positive      2  \n",
       "223191  no negative the very friendly and helpful staf...      2  \n",
       "282475   breakfast could have been better  nice hotel ...      2  \n",
       "436370   breakfast staff not all really helpful a litt...      2  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "# df['Reviews_Clean_2'] = df['Reviews_Clean'].apply(lambda x: [item for item in x if item not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T18:58:10.915917Z",
     "start_time": "2020-12-11T18:58:09.190656Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-155f2e6e60ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fit and transform dataframe without data cleaning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Reviews_Clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_tk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf_tk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m-> 1199\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             raise ValueError(\"np.nan is an invalid document, expected byte or \"\n\u001b[0m\u001b[1;32m    220\u001b[0m                              \"unicode string.\")\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fit and transform dataframe without data cleaning\n",
    "df_cv = cv.fit_transform(df['Reviews_Clean'])\n",
    "df_tk = pd.DataFrame(df_cv.toarray(), columns = cv.get_feature_names())\n",
    "df_tk.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T18:58:37.203359Z",
     "start_time": "2020-12-11T18:58:12.066167Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_tk_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T18:00:04.074658Z",
     "start_time": "2020-12-11T17:59:59.718708Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using Sparse in the DataFrame\n",
    "df_sparse = df_tk.astype('Sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T14:32:06.085322Z",
     "start_time": "2020-12-11T14:30:50.796556Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sparse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T16:29:37.642313Z",
     "start_time": "2020-12-11T14:33:59.583690Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sparse.to_csv('sparse_data.csv')\n",
    "# df.to_csv(\"csv/df_sentiment_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T02:22:04.923961Z",
     "start_time": "2020-12-11T02:22:04.919988Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df.Score\n",
    "X = df_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T02:22:04.933041Z",
     "start_time": "2020-12-11T02:22:04.927281Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T02:24:15.308694Z",
     "start_time": "2020-12-11T02:22:04.936317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Running Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.25)\n",
    "\n",
    "# This cell takes around 2 minutes to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T02:24:15.331816Z",
     "start_time": "2020-12-11T02:24:15.315219Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T02:32:46.552336Z",
     "start_time": "2020-12-11T02:24:15.336464Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline Regression Model\n",
    "logreg_base = LogisticRegression()\n",
    "logreg_base.fit(X_train, y_train) \n",
    "y_logreg_base = logreg_base.predict(X_test)\n",
    "\n",
    "# 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T17:43:04.508325Z",
     "start_time": "2020-12-11T17:43:04.491944Z"
    }
   },
   "outputs": [],
   "source": [
    "# Logistic Regression baseline evaluation\n",
    "evaluation(y_test, y_logreg_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas\n",
    "\n",
    "- Check if the review is worse if it takes time to be made\n",
    "- Check the country and nationalities\n",
    "- Time of the year with more complaints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stretch Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Get latitude and longitude for hotels that are missing this information\n",
    "- People might base their review on an isolated bad experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-11T03:04:52.816026Z",
     "start_time": "2020-12-11T03:04:51.534293Z"
    }
   },
   "outputs": [],
   "source": [
    "''' getting hotels latitude and longetude '''\n",
    "\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "# 1 - conveneint function to delay between geocoding calls\n",
    "geocode = RateLimiter(locator.geocode, min_delay_seconds=1)\n",
    "# 2- - create location column\n",
    "df['location'] = df['ADDRESS'].apply(geocode)\n",
    "# 3 - create longitude, laatitude and altitude from location column (returns tuple)\n",
    "df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "# 4 - split point column into latitude, longitude and altitude columns\n",
    "df[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df['point'].tolist(), index=df.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
