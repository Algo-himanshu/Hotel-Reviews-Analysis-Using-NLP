{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models Using a Dense Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find the baseline models, also known as vanilla models. For the baseline models, I will run Logistic Regression, which is a basic but reliable model - it works well with binary classification?; Random Forest because I believe a Decision Tree could bring me good results but since Random Forest is a collection of Decision Trees, I can skip it and start with Random Forest; Naive Bayes, which is know for giving good results when applied to NLP; and Support Vector Machine, which is also known for working well with Natural Language Processing.\n",
    "\n",
    "I will try the vanilla models with the datasets vectorized with CountVectorizer, TF-IDF. I will try these models with and without lemmatization. I will also iterate the best models with a train set using SMOTE. I have fixed the class imbalance manually in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/preprossessing/data-cleaning.ipynb\">Data Cleaning</a> notebook. However, I'm curious to see if the models could have any improvement with SMOTE. I will use the `Spell_Checked` feature, since it's the cleanest one. I will not include other features from the original data set because the main objective is train a model using the reviews only.\n",
    "\n",
    "I have a binary classification, where the target will be 0 for negative review and 1 for positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprossess the dataset creating train and test datasets\n",
    "- Run models for each vectorizer used\n",
    "- Find the best models for each category\n",
    "- Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import important packages and the data set we will use, which was already cleaned in the Data Cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:23.532490Z",
     "start_time": "2020-12-23T04:00:20.985945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP Packages\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Solve warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Import pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the main dataset and the lemmatized X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:23.813695Z",
     "start_time": "2020-12-23T04:00:23.534986Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing cleaned dataset as a DataFrame\n",
    "df = pd.read_csv('../csv/Hotel_Review_Spell_Checked.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:23.856845Z",
     "start_time": "2020-12-23T04:00:23.818645Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Reviews_Clean</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spell_Checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185010</td>\n",
       "      <td>St James Court A Taj Hotel London</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>the location was perfect</td>\n",
       "      <td>9.6</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "      <td>1</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424531</td>\n",
       "      <td>H10 Metropolitan 4 Sup</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Everything was top notch staff were impeccable</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                         Hotel_Name Negative_Review  \\\n",
       "0        185010  St James Court A Taj Hotel London     No Negative   \n",
       "1        424531             H10 Metropolitan 4 Sup        Nothing    \n",
       "\n",
       "                                    Positive_Review  Reviewer_Score  \\\n",
       "0                         the location was perfect              9.6   \n",
       "1   Everything was top notch staff were impeccable             10.0   \n",
       "\n",
       "                                       Reviews_Clean  Score  \\\n",
       "0              no negative the location was perfect       1   \n",
       "1   nothing  everything was top notch staff were ...      1   \n",
       "\n",
       "                                       Spell_Checked  \n",
       "0              no negative the location was perfect   \n",
       "1   nothing  everything was top notch staff were ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking DataFrame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:23.867505Z",
     "start_time": "2020-12-23T04:00:23.860336Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing stop_words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:23.894025Z",
     "start_time": "2020-12-23T04:00:23.870668Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping null values, if any\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the introduction, I will use the column `Spell_Checked` to create the features and `Score` as my target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:24.486368Z",
     "start_time": "2020-12-23T04:00:24.483162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an X variable and y for my target\n",
    "X = df.Spell_Checked\n",
    "y = df.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:24.805590Z",
     "start_time": "2020-12-23T04:00:24.796640Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset in train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:26.590600Z",
     "start_time": "2020-12-23T04:00:25.787975Z"
    }
   },
   "outputs": [],
   "source": [
    "# instantiate vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# fit to training data's string_cleaned column and \n",
    "# transform train and test sets\n",
    "X_train_vec_matrix = vectorizer.fit_transform(\n",
    "    X_train)\n",
    "X_test_vec_matrix = vectorizer.transform(\n",
    "    X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:07:20.943658Z",
     "start_time": "2020-12-23T04:07:20.939804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<16214x10780 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 314124 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:35.365659Z",
     "start_time": "2020-12-23T04:00:26.592800Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert tf-idf vectors into dataframe so I can better view \n",
    "# feature importances\n",
    "X_train_vec = pd.DataFrame.sparse.from_spmatrix(\n",
    "    X_train_vec_matrix, columns=vectorizer.get_feature_names())\n",
    "X_test_vec = pd.DataFrame.sparse.from_spmatrix(\n",
    "    X_test_vec_matrix, columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric below will simplify the model evaluation. My main focus is the accuracy metric. Have an accurate is important to be accurate. However, although fixing False Negatives is not crucial, I will also take a look at Recall and F1-Score to understand how my model is working. Since it is not my main focus, I will not mentioned in the individual analysis on my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:01:45.998620Z",
     "start_time": "2020-12-23T04:01:45.993078Z"
    }
   },
   "outputs": [],
   "source": [
    "# %load ../functions/evaluation.py\n",
    "# Evaluation function\n",
    "\n",
    "def evaluation(y_true, y_pred):\n",
    "\n",
    "    print('Evaluation Metrics:')\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(metrics.precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(metrics.recall_score(y_true, y_pred)))\n",
    "    print('F1 Score: ' + str(metrics.f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:35.382269Z",
     "start_time": "2020-12-23T04:00:35.375182Z"
    }
   },
   "outputs": [],
   "source": [
    "vanilla_models = pd.read_csv('../csv/baseline-models_evaluations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF.\n",
    "\n",
    "I will also create dictionaries for each model so that I will be able to create a DataFrame with the models' results. For better visualization, I will evaluate each model by the end of each section.\n",
    "\n",
    "\n",
    "<b>Note:</b> You will see that I will instantiate the same model multiple times. This will be done so that you can run each model individually, without having the run all the cells for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:38.500384Z",
     "start_time": "2020-12-23T04:00:35.384392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_lg = lg.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:38.520617Z",
     "start_time": "2020-12-23T04:00:38.502434Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_accuracy = accuracy_score(y_test, y_pred_lg)\n",
    "lr_precision = precision_score(y_test, y_pred_lg)\n",
    "lr_recall = recall_score(y_test, y_pred_lg)\n",
    "lr_f1 = f1_score(y_test, y_pred_lg)\n",
    "\n",
    "metric_dict = {}\n",
    "metric_dict['Baseline Logisitic Regression - Dense Matrix'] = {'Accuracy': lr_accuracy,\n",
    "                                                'Precision': lr_precision,\n",
    "                                                'Recall': lr_recall,\n",
    "                                                'F1 Score': lr_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:38.542885Z",
     "start_time": "2020-12-23T04:00:38.524552Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8170212765957446\n",
      "Precision: 0.8481936971560338\n",
      "Recall: 0.7879328811138879\n",
      "F1 Score: 0.8169535443272257\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression baseline evaluation\n",
    "evaluation(y_test, y_pred_lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:00:45.099667Z",
     "start_time": "2020-12-23T04:00:45.083037Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.866057</td>\n",
       "      <td>0.777936</td>\n",
       "      <td>0.819635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense Matrix</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.805365</td>\n",
       "      <td>0.842270</td>\n",
       "      <td>0.768297</td>\n",
       "      <td>0.803585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.803515</td>\n",
       "      <td>0.843812</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.800750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.802035</td>\n",
       "      <td>0.833467</td>\n",
       "      <td>0.760249</td>\n",
       "      <td>0.795176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Accuracy  Precision    Recall  \\\n",
       "Baseline SVC TF-IDF                           0.822202   0.862205  0.781864   \n",
       "Baseline SVC SMOTE                            0.822572   0.866057  0.777936   \n",
       "Baseline Random Forest Lem                    0.823127   0.849331  0.790264   \n",
       "Baseline Logisitic Regression - Dense Matrix  0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression TF-IDF           0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression Lem              0.817761   0.831499  0.801977   \n",
       "Baseline Logisitic Regression - Dense         0.798150   0.810458  0.796858   \n",
       "Baseline Random Forest CV                     0.805365   0.842270  0.768297   \n",
       "Baseline Random Forest TF-IDF                 0.803515   0.843812  0.761871   \n",
       "Baseline Random Forest SMOTE                  0.802035   0.833467  0.760249   \n",
       "Baseline SVC CV                               0.783904   0.794234  0.786862   \n",
       "Baseline Naive Bayes CV                       0.781129   0.793541  0.780793   \n",
       "\n",
       "                                              F1 Score  \n",
       "Baseline SVC TF-IDF                           0.820071  \n",
       "Baseline SVC SMOTE                            0.819635  \n",
       "Baseline Random Forest Lem                    0.818733  \n",
       "Baseline Logisitic Regression - Dense Matrix  0.816954  \n",
       "Baseline Logistic Regression TF-IDF           0.816954  \n",
       "Baseline Logistic Regression Lem              0.816471  \n",
       "Baseline Logisitic Regression - Dense         0.803600  \n",
       "Baseline Random Forest CV                     0.803585  \n",
       "Baseline Random Forest TF-IDF                 0.800750  \n",
       "Baseline Random Forest SMOTE                  0.795176  \n",
       "Baseline SVC CV                               0.790531  \n",
       "Baseline Naive Bayes CV                       0.787115  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation = pd.concat([evaluation_df, vanilla_models])\n",
    "evaluation.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, Logistic Regression performed quite well with an accuracy of 0.7981. My main metric is accuracy and it seems that Logistic Regression is able to correctly understand the positive and negative reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:01:21.623651Z",
     "start_time": "2020-12-23T04:01:14.043996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_rf = rf.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:01:21.648692Z",
     "start_time": "2020-12-23T04:01:21.626487Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
    "rf_precision = precision_score(y_test, y_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "metric_dict['Baseline Random Forest - Dense Matrix'] = {'Accuracy': rf_accuracy,\n",
    "                                                'Precision': rf_precision,\n",
    "                                                'Recall': rf_recall,\n",
    "                                                'F1 Score': rf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:01:51.176013Z",
     "start_time": "2020-12-23T04:01:51.157327Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8098057354301572\n",
      "Precision: 0.8464243845252052\n",
      "Recall: 0.7732952516958229\n",
      "F1 Score: 0.8082089552238805\n"
     ]
    }
   ],
   "source": [
    "# Random Forest baseline evaluation\n",
    "evaluation(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:01:54.153974Z",
     "start_time": "2020-12-23T04:01:54.137638Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.866057</td>\n",
       "      <td>0.777936</td>\n",
       "      <td>0.819635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense Matrix</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest - Dense Matrix</th>\n",
       "      <td>0.809806</td>\n",
       "      <td>0.846424</td>\n",
       "      <td>0.773295</td>\n",
       "      <td>0.808209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.805365</td>\n",
       "      <td>0.842270</td>\n",
       "      <td>0.768297</td>\n",
       "      <td>0.803585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.803515</td>\n",
       "      <td>0.843812</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.800750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.802035</td>\n",
       "      <td>0.833467</td>\n",
       "      <td>0.760249</td>\n",
       "      <td>0.795176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Accuracy  Precision    Recall  \\\n",
       "Baseline SVC TF-IDF                           0.822202   0.862205  0.781864   \n",
       "Baseline SVC SMOTE                            0.822572   0.866057  0.777936   \n",
       "Baseline Random Forest Lem                    0.823127   0.849331  0.790264   \n",
       "Baseline Logisitic Regression - Dense Matrix  0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression TF-IDF           0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression Lem              0.817761   0.831499  0.801977   \n",
       "Baseline Random Forest - Dense Matrix         0.809806   0.846424  0.773295   \n",
       "Baseline Logisitic Regression - Dense         0.798150   0.810458  0.796858   \n",
       "Baseline Random Forest CV                     0.805365   0.842270  0.768297   \n",
       "Baseline Random Forest TF-IDF                 0.803515   0.843812  0.761871   \n",
       "Baseline Random Forest SMOTE                  0.802035   0.833467  0.760249   \n",
       "Baseline SVC CV                               0.783904   0.794234  0.786862   \n",
       "Baseline Naive Bayes CV                       0.781129   0.793541  0.780793   \n",
       "\n",
       "                                              F1 Score  \n",
       "Baseline SVC TF-IDF                           0.820071  \n",
       "Baseline SVC SMOTE                            0.819635  \n",
       "Baseline Random Forest Lem                    0.818733  \n",
       "Baseline Logisitic Regression - Dense Matrix  0.816954  \n",
       "Baseline Logistic Regression TF-IDF           0.816954  \n",
       "Baseline Logistic Regression Lem              0.816471  \n",
       "Baseline Random Forest - Dense Matrix         0.808209  \n",
       "Baseline Logisitic Regression - Dense         0.803600  \n",
       "Baseline Random Forest CV                     0.803585  \n",
       "Baseline Random Forest TF-IDF                 0.800750  \n",
       "Baseline Random Forest SMOTE                  0.795176  \n",
       "Baseline SVC CV                               0.790531  \n",
       "Baseline Naive Bayes CV                       0.787115  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation = pd.concat([evaluation_df, vanilla_models])\n",
    "evaluation.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest was able to do slightly better than Logistic Regression with an accuracy of 0.8031. Let's see if other models are able to perform better than that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:03:48.056860Z",
     "start_time": "2020-12-23T04:03:46.935574Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "nb_base_cv = MultinomialNB(alpha = .01)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "nb_base_cv.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_nb_base_cv = nb_base_cv.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:03:55.840120Z",
     "start_time": "2020-12-23T04:03:55.822293Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "nb_cv_accuracy = accuracy_score(y_test, y_nb_base_cv)\n",
    "nb_cv_precision = precision_score(y_test, y_nb_base_cv)\n",
    "nb_cv_recall = recall_score(y_test, y_nb_base_cv)\n",
    "nb_cv_f1 = f1_score(y_test, y_nb_base_cv)\n",
    "\n",
    "metric_dict['Baseline Naive Bayes - Dense Matrix'] = {'Accuracy': nb_cv_accuracy,\n",
    "                                                'Precision': nb_cv_precision,\n",
    "                                                'Recall': nb_cv_recall,\n",
    "                                                'F1 Score': nb_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:04:47.003721Z",
     "start_time": "2020-12-23T04:04:46.989629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.866057</td>\n",
       "      <td>0.777936</td>\n",
       "      <td>0.819635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense Matrix</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest - Dense Matrix</th>\n",
       "      <td>0.809806</td>\n",
       "      <td>0.846424</td>\n",
       "      <td>0.773295</td>\n",
       "      <td>0.808209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression - Dense</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.805365</td>\n",
       "      <td>0.842270</td>\n",
       "      <td>0.768297</td>\n",
       "      <td>0.803585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.803515</td>\n",
       "      <td>0.843812</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.800750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.802035</td>\n",
       "      <td>0.833467</td>\n",
       "      <td>0.760249</td>\n",
       "      <td>0.795176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes - Dense Matrix</th>\n",
       "      <td>0.769843</td>\n",
       "      <td>0.793884</td>\n",
       "      <td>0.750803</td>\n",
       "      <td>0.771743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Accuracy  Precision    Recall  \\\n",
       "Baseline SVC TF-IDF                           0.822202   0.862205  0.781864   \n",
       "Baseline SVC SMOTE                            0.822572   0.866057  0.777936   \n",
       "Baseline Random Forest Lem                    0.823127   0.849331  0.790264   \n",
       "Baseline Logisitic Regression - Dense Matrix  0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression TF-IDF           0.817021   0.848194  0.787933   \n",
       "Baseline Logistic Regression Lem              0.817761   0.831499  0.801977   \n",
       "Baseline Random Forest - Dense Matrix         0.809806   0.846424  0.773295   \n",
       "Baseline Logisitic Regression - Dense         0.798150   0.810458  0.796858   \n",
       "Baseline Random Forest CV                     0.805365   0.842270  0.768297   \n",
       "Baseline Random Forest TF-IDF                 0.803515   0.843812  0.761871   \n",
       "Baseline Random Forest SMOTE                  0.802035   0.833467  0.760249   \n",
       "Baseline SVC CV                               0.783904   0.794234  0.786862   \n",
       "Baseline Naive Bayes CV                       0.781129   0.793541  0.780793   \n",
       "Baseline Naive Bayes - Dense Matrix           0.769843   0.793884  0.750803   \n",
       "\n",
       "                                              F1 Score  \n",
       "Baseline SVC TF-IDF                           0.820071  \n",
       "Baseline SVC SMOTE                            0.819635  \n",
       "Baseline Random Forest Lem                    0.818733  \n",
       "Baseline Logisitic Regression - Dense Matrix  0.816954  \n",
       "Baseline Logistic Regression TF-IDF           0.816954  \n",
       "Baseline Logistic Regression Lem              0.816471  \n",
       "Baseline Random Forest - Dense Matrix         0.808209  \n",
       "Baseline Logisitic Regression - Dense         0.803600  \n",
       "Baseline Random Forest CV                     0.803585  \n",
       "Baseline Random Forest TF-IDF                 0.800750  \n",
       "Baseline Random Forest SMOTE                  0.795176  \n",
       "Baseline SVC CV                               0.790531  \n",
       "Baseline Naive Bayes CV                       0.787115  \n",
       "Baseline Naive Bayes - Dense Matrix           0.771743  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation = pd.concat([evaluation_df, vanilla_models])\n",
    "evaluation.sort_values(by='F1 Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:04:23.817711Z",
     "start_time": "2020-12-23T04:04:23.803288Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-dea6928eac18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Naive Bayes baseline evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_nb_base_cv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "# Naive Bayes baseline evaluation\n",
    "evaluation(y_test, y_nb_base_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes didn't perform as well as Logistic Regression and Random Forest. It's a little surprising to me, since it's well known for being one of the best models for NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T04:03:17.391445Z",
     "start_time": "2020-12-23T04:03:16.749420Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "var not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-0af2c584b2d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Fitting the model to the X and y variables of the train set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Predicting the model in the X variable of the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;31m# var = E[X^2] - E[X]^2 if sparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 X_var = ((X.multiply(X)).mean() - (X.mean()) ** 2\n\u001b[0;32m--> 200\u001b[0;31m                          if sparse else X.var())\n\u001b[0m\u001b[1;32m    201\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mX_var\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_var\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: var not found"
     ]
    }
   ],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc = svc.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.279000Z",
     "start_time": "2020-12-17T20:57:55.258923Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_cv_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "svc_cv_precision = precision_score(y_test, y_pred_svc)\n",
    "svc_cv_recall = recall_score(y_test, y_pred_svc)\n",
    "svc_cv_f1 = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "metric_dict['Baseline SVC CV'] = {'Accuracy': svc_cv_accuracy,\n",
    "                                  'Precision': svc_cv_precision,\n",
    "                                  'Recall': svc_cv_recall,\n",
    "                                  'F1 Score': svc_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.304204Z",
     "start_time": "2020-12-17T20:57:55.282296Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7839037927844589\n",
      "Precision: 0.7942342342342342\n",
      "Recall: 0.7868618350589075\n",
      "F1 Score: 0.7905308464849354\n"
     ]
    }
   ],
   "source": [
    "# SVC baseline evaluation\n",
    "evaluation(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC also didn't perform as well as Logistic Regression and Random Forest. It had an accuracy of 0.7839. However, it performed better than Naive Bayes. Thus, I will run some further iterations with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.322631Z",
     "start_time": "2020-12-17T20:57:55.306935Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.760086</td>\n",
       "      <td>0.797378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Random Forest CV         0.799815   0.838519  0.760086  0.797378\n",
       "Baseline Logisitic Regression CV  0.798150   0.810458  0.796858  0.803600\n",
       "Baseline SVC CV                   0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Naive Bayes CV           0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the models performed quite well for baseline models. The three best models were Random Forest, Logistic Regression, and SVC. Naive Bayes did a good job as well, but it under performed if compared to the other models in the accuracy metric, which is my focus for this project.\n",
    "\n",
    "It is interesting to see that Logistic Regression performed in second place between these baseline models. It tells us that although not usually seen as a powerful model, it holds it's surprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will see how each of the three best models in the previous section performs when using the TF-IDF vectorizer. Too keep each to read, the evaluations will be at the end of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:50:09.603443Z",
     "start_time": "2020-12-23T01:50:06.619680Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_baseline = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_baseline.fit(X_train_vec, y_train) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_base_tfidf = lg_baseline.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:50:20.138928Z",
     "start_time": "2020-12-23T01:50:20.118392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8170212765957446\n",
      "Precision: 0.8481936971560338\n",
      "Recall: 0.7879328811138879\n",
      "F1 Score: 0.8169535443272257\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_lg_base_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:50:38.127907Z",
     "start_time": "2020-12-23T01:50:38.125456Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = lg_baseline.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:50:44.921439Z",
     "start_time": "2020-12-23T01:50:44.917826Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i,v in enumerate(importance):\n",
    "#     print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "# # plot feature importance\n",
    "# pyplot.bar([x for x in range(len(importance))], importance)\n",
    "# pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.642789Z",
     "start_time": "2020-12-17T20:57:55.325649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_baseline = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_baseline.fit(X_train_tfidf, y_train) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_base_tfidf = lg_baseline.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.669582Z",
     "start_time": "2020-12-17T20:57:55.645583Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lg_tfidf_accuracy = accuracy_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_precision = precision_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_recall = recall_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_f1 = f1_score(y_test, y_lg_base_tfidf)\n",
    "\n",
    "metric_dict['Baseline Logistic Regression TF-IDF'] = {'Accuracy': lg_tfidf_accuracy,\n",
    "                                                'Precision': lg_tfidf_precision,\n",
    "                                                'Recall': lg_tfidf_recall,\n",
    "                                                'F1 Score': lg_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:57:55.695506Z",
     "start_time": "2020-12-17T20:57:55.672128Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8170212765957446\n",
      "Precision: 0.8481936971560338\n",
      "Recall: 0.7879328811138879\n",
      "F1 Score: 0.8169535443272257\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_lg_base_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement with Logistic Regressing and TF-IDF. The accuracy improved from 0.7981 to 0.8170."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:52:21.077768Z",
     "start_time": "2020-12-23T01:51:59.644973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "rf_baseline = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_vec, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_base_tfidf = rf_baseline.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T20:58:19.473806Z",
     "start_time": "2020-12-17T20:58:19.455123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_tfidf_accuracy = accuracy_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_precision = precision_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_recall = recall_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_f1 = f1_score(y_test, y_rf_base_tfidf)\n",
    "\n",
    "metric_dict['Baseline Random Forest TF-IDF'] = {'Accuracy': rf_tfidf_accuracy,\n",
    "                                                'Precision': rf_tfidf_precision,\n",
    "                                                'Recall': rf_tfidf_recall,\n",
    "                                                'F1 Score': rf_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:54:11.784012Z",
     "start_time": "2020-12-23T01:54:11.765581Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.801295097132285\n",
      "Precision: 0.8374364986322782\n",
      "Recall: 0.7650838986076401\n",
      "F1 Score: 0.7996268656716418\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_rf_base_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:45:22.578292Z",
     "start_time": "2020-12-23T01:45:22.534635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.46555337e-08, 1.64334173e-07, 0.00000000e+00, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.46837382e-05])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_baseline.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:54:17.204169Z",
     "start_time": "2020-12-23T01:54:17.155559Z"
    }
   },
   "outputs": [],
   "source": [
    "features_dict = dict(zip(X_train_vec.columns, rf_baseline.feature_importances_))\n",
    "features_rf = pd.DataFrame.from_dict(features_dict, orient='index')\n",
    "features_rf.nlargest(20, 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:54:17.858645Z",
     "start_time": "2020-12-23T01:54:17.832506Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>negative</th>\n",
       "      <th>positive</th>\n",
       "      <th>great</th>\n",
       "      <th>excellent</th>\n",
       "      <th>staff</th>\n",
       "      <th>location</th>\n",
       "      <th>room</th>\n",
       "      <th>friendly</th>\n",
       "      <th>comfortable</th>\n",
       "      <th>poor</th>\n",
       "      <th>breakfast</th>\n",
       "      <th>dirty</th>\n",
       "      <th>good</th>\n",
       "      <th>helpful</th>\n",
       "      <th>small</th>\n",
       "      <th>lovely</th>\n",
       "      <th>nice</th>\n",
       "      <th>old</th>\n",
       "      <th>bad</th>\n",
       "      <th>perfect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042552</td>\n",
       "      <td>0.025359</td>\n",
       "      <td>0.019064</td>\n",
       "      <td>0.017856</td>\n",
       "      <td>0.01239</td>\n",
       "      <td>0.012372</td>\n",
       "      <td>0.012289</td>\n",
       "      <td>0.011284</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.009927</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.008691</td>\n",
       "      <td>0.008556</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.007981</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.007697</td>\n",
       "      <td>0.006573</td>\n",
       "      <td>0.006495</td>\n",
       "      <td>0.006362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   negative  positive     great  excellent    staff  location      room  \\\n",
       "0  0.042552  0.025359  0.019064   0.017856  0.01239  0.012372  0.012289   \n",
       "\n",
       "   friendly  comfortable      poor  breakfast     dirty      good   helpful  \\\n",
       "0  0.011284     0.010039  0.009927   0.009014  0.008691  0.008556  0.008551   \n",
       "\n",
       "      small    lovely      nice       old       bad   perfect  \n",
       "0  0.007981  0.007763  0.007697  0.006573  0.006495  0.006362  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_rf.nlargest(20, 0).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with TF-IDF also performed slightly better than when I tried it with Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:43:18.063837Z",
     "start_time": "2020-12-15T16:43:18.061209Z"
    }
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:06.594690Z",
     "start_time": "2020-12-17T20:58:19.498236Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline SVC Model\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc_tfidf = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:06.615284Z",
     "start_time": "2020-12-17T21:00:06.597019Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_tfidf_accuracy = accuracy_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_precision = precision_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_recall = recall_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_f1 = f1_score(y_test, y_pred_svc_tfidf)\n",
    "\n",
    "metric_dict['Baseline SVC TF-IDF'] = {'Accuracy': svc_tfidf_accuracy,\n",
    "                                                'Precision': svc_tfidf_precision,\n",
    "                                                'Recall': svc_tfidf_recall,\n",
    "                                                'F1 Score': svc_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:06.638903Z",
     "start_time": "2020-12-17T21:00:06.617792Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8222016651248844\n",
      "Precision: 0.8622047244094488\n",
      "Recall: 0.7818636201356658\n",
      "F1 Score: 0.8200711477251451\n"
     ]
    }
   ],
   "source": [
    "# SVC TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_pred_svc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC had a good improvement in accuracy. It went from 0.7839 to 0.8222. It is the best model so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:06.654667Z",
     "start_time": "2020-12-17T21:00:06.641316Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.760086</td>\n",
       "      <td>0.797378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.793531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline SVC TF-IDF                  0.822202   0.862205  0.781864  0.820071\n",
       "Baseline Logistic Regression TF-IDF  0.817021   0.848194  0.787933  0.816954\n",
       "Baseline Random Forest CV            0.799815   0.838519  0.760086  0.797378\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest TF-IDF        0.796855   0.838300  0.753302  0.793531\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that all the models using TF-IDF had a better performance than the models using CountVectorizer. SVC model had an big improvement compared to other models and Logistic Regression was able to perform better than Random Forest, which is surprising. The model that had the lowest improvement was Random Forest, which we can see that it changed very little.\n",
    "\n",
    "I will now test these three models with the lemmatized dataset and see if there is any improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF With Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try the three best models using the lemmatized variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:51:14.902024Z",
     "start_time": "2020-12-23T01:51:13.424808Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lr_baseline = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lr_baseline.fit(X_train_vec, y_train) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lr_base_tfidf_lem = lr_baseline.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:50:59.476083Z",
     "start_time": "2020-12-23T01:50:59.461837Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_lem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-cd9040a501e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Creating dictionary with all metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlr_lem_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lr_base_tfidf_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlr_lem_precision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lr_base_tfidf_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlr_lem_recall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lr_base_tfidf_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlr_lem_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lr_base_tfidf_lem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_lem' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_lem_accuracy = accuracy_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_precision = precision_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_recall = recall_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_f1 = f1_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "\n",
    "metric_dict['Baseline Logistic Regression Lem'] = {'Accuracy': lr_lem_accuracy,\n",
    "                                                'Precision': lr_lem_precision,\n",
    "                                                'Recall': lr_lem_recall,\n",
    "                                                'F1 Score': lr_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-23T01:51:24.314829Z",
     "start_time": "2020-12-23T01:51:24.303523Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test_lem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-54a6a987af95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic Regression TF-IDF baseline evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_lr_base_tfidf_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test_lem' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_lr_base_tfidf_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iteration performed slightly better than the iteration without lemmatization: 0.81777 vs 0.81770. However, it's insignificant. Thus, I'll consider  the precision metric to decide which model will move forward. In this case, it will be the model without lemmatizaiton."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:01:00.400618Z",
     "start_time": "2020-12-17T21:00:36.994301Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_baseline = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_lem, y_train_lem) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_base_lem = rf_baseline.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:01:00.421396Z",
     "start_time": "2020-12-17T21:01:00.402602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_lem_accuracy = accuracy_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_precision = precision_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_recall = recall_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_f1 = f1_score(y_test_lem, y_rf_base_lem)\n",
    "\n",
    "metric_dict['Baseline Random Forest Lem'] = {'Accuracy': rf_lem_accuracy,\n",
    "                                                'Precision': rf_lem_precision,\n",
    "                                                'Recall': rf_lem_recall,\n",
    "                                                'F1 Score': rf_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:01:00.441116Z",
     "start_time": "2020-12-17T21:01:00.424614Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7988899167437558\n",
      "Precision: 0.8196657598134474\n",
      "Recall: 0.7719619326500732\n",
      "F1 Score: 0.7950989632422243\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_rf_base_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with lemmatization is the best model so far with an accuracy of 0.8231 and 0.8048 without lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:02:36.731117Z",
     "start_time": "2020-12-17T21:01:00.444061Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline SVC Model\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_lem, y_train_lem)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc_lem = svc.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:02:36.748594Z",
     "start_time": "2020-12-17T21:02:36.732900Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_lem_accuracy = accuracy_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_precision = precision_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_recall = recall_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_f1 = f1_score(y_test_lem, y_pred_svc_lem)\n",
    "\n",
    "metric_dict['Baseline Random Forest Lem'] = {'Accuracy': svc_lem_accuracy,\n",
    "                                                'Precision': svc_lem_precision,\n",
    "                                                'Recall': svc_lem_recall,\n",
    "                                                'F1 Score': svc_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:02:36.768048Z",
     "start_time": "2020-12-17T21:02:36.750803Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8231267345050879\n",
      "Precision: 0.8493312352478364\n",
      "Recall: 0.7902635431918009\n",
      "F1 Score: 0.8187334091770953\n"
     ]
    }
   ],
   "source": [
    "# SCV TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_pred_svc_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:02:36.783043Z",
     "start_time": "2020-12-17T21:02:36.770496Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.760086</td>\n",
       "      <td>0.797378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.793531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Random Forest Lem           0.823127   0.849331  0.790264  0.818733\n",
       "Baseline SVC TF-IDF                  0.822202   0.862205  0.781864  0.820071\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Logistic Regression TF-IDF  0.817021   0.848194  0.787933  0.816954\n",
       "Baseline Random Forest CV            0.799815   0.838519  0.760086  0.797378\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest TF-IDF        0.796855   0.838300  0.753302  0.793531\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Random Forest is our best model so far compared to all the previous model. However, the baseline SVC model using TF-IDF is very close to it with a higher precision and higher F1 Score. They aren't my main focus when it comes to metrics, but I might take in consideration when choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fixed the class imbalance manually. However, I'm curious to see how my best models will behave using SMOTE. For this reason I'll run two of my best models and see how it would perform with SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:02:42.792995Z",
     "start_time": "2020-12-17T21:02:36.787075Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_smote_lem, y_train_smote_lem = smote.fit_sample(X_train_lem, y_train_lem) \n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote_tfidf, y_train_smote_tfidf = smote.fit_sample(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:03:06.914897Z",
     "start_time": "2020-12-17T21:02:42.795744Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_base_lem_tfidf = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_base_lem_tfidf.fit(X_train_smote_lem, y_train_smote_lem)\n",
    "\n",
    "# Predicting the model in the X variable of the test set### Random Forest\n",
    "y_rf_base_lem_tfidf_smote = rf_base_lem_tfidf.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:03:06.952805Z",
     "start_time": "2020-12-17T21:03:06.918042Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_smote_accuracy = accuracy_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_precision = precision_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_recall = recall_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_f1 = f1_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "\n",
    "metric_dict['Baseline Random Forest SMOTE'] = {'Accuracy': rf_smote_accuracy,\n",
    "                                                'Precision': rf_smote_precision,\n",
    "                                                'Recall': rf_smote_recall,\n",
    "                                                'F1 Score': rf_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:03:06.986514Z",
     "start_time": "2020-12-17T21:03:06.955822Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8003700277520814\n",
      "Precision: 0.8291517323775388\n",
      "Recall: 0.7620790629575402\n",
      "F1 Score: 0.7942017928666795\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test_lem, y_rf_base_lem_tfidf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest did not perform any better using SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:40:32.733033Z",
     "start_time": "2020-12-16T19:40:32.730826Z"
    }
   },
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:05:05.416281Z",
     "start_time": "2020-12-17T21:03:06.991775Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_smote_tfidf, y_train_smote_tfidf)\n",
    "y_pred_svc_smote = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:05:05.435579Z",
     "start_time": "2020-12-17T21:05:05.418346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_smote_accuracy = accuracy_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_precision = precision_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_recall = recall_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_f1 = f1_score(y_test, y_pred_svc_smote)\n",
    "\n",
    "metric_dict['Baseline SVC SMOTE'] = {'Accuracy': svc_smote_accuracy,\n",
    "                                                'Precision': svc_smote_precision,\n",
    "                                                'Recall': svc_smote_recall,\n",
    "                                                'F1 Score': svc_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:05:05.454395Z",
     "start_time": "2020-12-17T21:05:05.437806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8223866790009251\n",
      "Precision: 0.863690241011458\n",
      "Recall: 0.7804355587290254\n",
      "F1 Score: 0.8199549887471868\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred_svc_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:05:05.470669Z",
     "start_time": "2020-12-17T21:05:05.456753Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.822387</td>\n",
       "      <td>0.863690</td>\n",
       "      <td>0.780436</td>\n",
       "      <td>0.819955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.800370</td>\n",
       "      <td>0.829152</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.794202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.760086</td>\n",
       "      <td>0.797378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.793531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Random Forest Lem           0.823127   0.849331  0.790264  0.818733\n",
       "Baseline SVC SMOTE                   0.822387   0.863690  0.780436  0.819955\n",
       "Baseline SVC TF-IDF                  0.822202   0.862205  0.781864  0.820071\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Logistic Regression TF-IDF  0.817021   0.848194  0.787933  0.816954\n",
       "Baseline Random Forest SMOTE         0.800370   0.829152  0.762079  0.794202\n",
       "Baseline Random Forest CV            0.799815   0.838519  0.760086  0.797378\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest TF-IDF        0.796855   0.838300  0.753302  0.793531\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the SMOTE was able to improve the accuracy metric by a very small different. However, Recall and F1 Score dropped, which tells me that the model is not as good as the version without SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:47:12.077415Z",
     "start_time": "2020-12-16T19:47:12.075016Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:05:05.486842Z",
     "start_time": "2020-12-17T21:05:05.473106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.823127</td>\n",
       "      <td>0.849331</td>\n",
       "      <td>0.790264</td>\n",
       "      <td>0.818733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.822387</td>\n",
       "      <td>0.863690</td>\n",
       "      <td>0.780436</td>\n",
       "      <td>0.819955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.822202</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.781864</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.800370</td>\n",
       "      <td>0.829152</td>\n",
       "      <td>0.762079</td>\n",
       "      <td>0.794202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.799815</td>\n",
       "      <td>0.838519</td>\n",
       "      <td>0.760086</td>\n",
       "      <td>0.797378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.796855</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.753302</td>\n",
       "      <td>0.793531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Random Forest Lem           0.823127   0.849331  0.790264  0.818733\n",
       "Baseline SVC SMOTE                   0.822387   0.863690  0.780436  0.819955\n",
       "Baseline SVC TF-IDF                  0.822202   0.862205  0.781864  0.820071\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Logistic Regression TF-IDF  0.817021   0.848194  0.787933  0.816954\n",
       "Baseline Random Forest SMOTE         0.800370   0.829152  0.762079  0.794202\n",
       "Baseline Random Forest CV            0.799815   0.838519  0.760086  0.797378\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest TF-IDF        0.796855   0.838300  0.753302  0.793531\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running multiple baseline models, we were able to verify a few points:\n",
    "- Our best model was a Random Forest using lemmatized words. However, the F1 score was lower than other models. Since I will focus on F1 Score further in this project, the winner was SVC using TF-IDF. \n",
    "- Random Forest, CVC, and Logistic Regression are the best models to use in NLP in these cases\n",
    "- TF-IDF was able improve all all our models.\n",
    "- Naive Bayes was our worst model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:49:17.652700Z",
     "start_time": "2020-12-17T21:49:16.865492Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a confusion matrix\n",
    "plt.figure(figsize=(6, 7))\n",
    "mat = confusion_matrix(y_test, y_pred_svc_tfidf)\n",
    "\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Positive', 'Negative'], yticklabels=['Positive', 'Negative'], cmap=\"Blues\")\n",
    "plt.xlabel('True Label', fontsize= 18)\n",
    "plt.ylabel('Predicted Label', fontsize= 18)\n",
    "plt.title('Baseline SVC TF-IDF Confusion Matrix', fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "b, t = plt.ylim() \n",
    "t -= 0.05 \n",
    "plt.ylim(b, t) \n",
    "plt.savefig('../images/confusion-matrix-baseline-model.png', bbox_inches = \"tight\", pad_inches=.5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that my model was able to predict correctly 84.47% of the positive reviews and 72.10% of the negative reviews. This means that I need to improve my model's ability to better predict negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with my best models in mind, I will run a few ensemble models in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/models/ensemble-models.ipynb\">Data Cleaning</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling files for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.960104Z",
     "start_time": "2020-12-17T20:56:11.342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/vanilla_model_evaluation.pkl\",'wb')\n",
    "pickle.dump(evaluation_df, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.962509Z",
     "start_time": "2020-12-17T20:56:11.346Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_train_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.964535Z",
     "start_time": "2020-12-17T20:56:11.350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_test_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.966539Z",
     "start_time": "2020-12-17T20:56:11.354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train and Test Set  Target\n",
    "y_train.to_pickle(\"../pickle/y_train.pkl\")\n",
    "y_test.to_pickle(\"../pickle/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.968759Z",
     "start_time": "2020-12-17T20:56:11.358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_lem.pkl\",'wb')\n",
    "pickle.dump(X_train_lem, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.970855Z",
     "start_time": "2020-12-17T20:56:11.362Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_lem.pkl\",'wb')\n",
    "pickle.dump(X_test_lem, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T21:00:07.972763Z",
     "start_time": "2020-12-17T20:56:11.367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train and Test Set - Target\n",
    "y_train_lem.to_pickle(\"../pickle/y_train_lem.pkl\")\n",
    "y_test_lem.to_pickle(\"../pickle/y_test_lem.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
