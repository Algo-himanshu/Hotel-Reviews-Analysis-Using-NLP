{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find the baseline models, also known as vanilla models. For the baseline models, I will run Logistic Regression, which is a basic but reliable model - it works well with binary classification?; Random Forest because I believe a Decision Tree could bring me good results but since Random Forest is a collection of Decision Trees, I can skip it and start with Random Forest; Naive Bayes, which is know for giving good results when applied to NLP; and Support Vector Machine, which is also known for working well with Natural Language Processing.\n",
    "\n",
    "I will try the vanilla models with the datasets vectorized with CountVectorizer, TF-IDF. I will try these models with and without lemmatization. I will also iterate the best models with a train set using SMOTE. I have fixed the class imbalance manually in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/preprossessing/data-cleaning.ipynb\">Data Cleaning</a> notebook. However, I'm curious to see if the models could have any improvement with SMOTE. I will use the `Spell_Checked` feature, since it's the cleanest one. I will not include other features from the original data set because the main objective is train a model using the reviews only.\n",
    "\n",
    "I have a binary classification, where the target will be 0 for negative review and 1 for positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprossess the dataset creating train and test datasets\n",
    "- Run models for each vectorizer used\n",
    "- Find the best models for each category\n",
    "- Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import important packages and the data set we will use, which was already cleaned in the Data Cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:25:27.168772Z",
     "start_time": "2020-12-16T20:25:27.147532Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# NLP Packages\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Solve warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Import pickle\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the main dataset and the lemmatized X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:25:44.517508Z",
     "start_time": "2020-12-16T20:25:44.271541Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing cleaned dataset as a DataFrame\n",
    "df = pd.read_csv('../csv/Hotel_Review_Spell_Checked.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:47:42.803481Z",
     "start_time": "2020-12-16T19:47:42.769944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Reviews_Clean</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spell_Checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185010</td>\n",
       "      <td>St James Court A Taj Hotel London</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>the location was perfect</td>\n",
       "      <td>9.6</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "      <td>1</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424531</td>\n",
       "      <td>H10 Metropolitan 4 Sup</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Everything was top notch staff were impeccable</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                         Hotel_Name Negative_Review  \\\n",
       "0        185010  St James Court A Taj Hotel London     No Negative   \n",
       "1        424531             H10 Metropolitan 4 Sup        Nothing    \n",
       "\n",
       "                                    Positive_Review  Reviewer_Score  \\\n",
       "0                         the location was perfect              9.6   \n",
       "1   Everything was top notch staff were impeccable             10.0   \n",
       "\n",
       "                                       Reviews_Clean  Score  \\\n",
       "0              no negative the location was perfect       1   \n",
       "1   nothing  everything was top notch staff were ...      1   \n",
       "\n",
       "                                       Spell_Checked  \n",
       "0              no negative the location was perfect   \n",
       "1   nothing  everything was top notch staff were ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking DataFrame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Lemmatized X and Y Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I lemmatized the feature variable `Spell_Checked` in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/preprossessing/data-cleaning.ipynb\">Data Cleaning</a> notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:30:30.996317Z",
     "start_time": "2020-12-16T20:30:30.968539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing lemmatized X and y variable\n",
    "X_lem = pickle.load(open('../pickle/X_lem.pkl', 'rb'))\n",
    "y_lem = pd.read_pickle('../pickle/y_lem.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:30:41.103674Z",
     "start_time": "2020-12-16T20:30:41.095033Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing stop_words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:30:51.509643Z",
     "start_time": "2020-12-16T20:30:51.489194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping null values, if any\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the introduction, I will use the column `Spell_Checked` to create the features and `Score` as my target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:42:42.637969Z",
     "start_time": "2020-12-16T20:42:42.634296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an X variable and y for my target\n",
    "X = df.Spell_Checked\n",
    "y = df.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:42:43.399442Z",
     "start_time": "2020-12-16T20:42:43.388312Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset in train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split with Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:44:07.182549Z",
     "start_time": "2020-12-16T20:44:07.169965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the lemmatized dataset in train set and test set\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:44:08.586754Z",
     "start_time": "2020-12-16T20:44:07.864782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fitting into the train and test set\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:44:09.462336Z",
     "start_time": "2020-12-16T20:44:08.722742Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fitting into the train and test set\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-DF With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:44:10.542822Z",
     "start_time": "2020-12-16T20:44:10.027400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting into the lemmatized train and test set\n",
    "X_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "X_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation metric below will simplify the model evaluation. My main focus is the accuracy metric. Have an accurate is important to be accurate. However, although fixing False Negatives is not crucial, I will also take a look at Recall and F1-Score to understand how my model is working. Since it is not my main focus, I will not mentioned in the individual analysis on my models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:57:34.625786Z",
     "start_time": "2020-12-16T20:57:34.620972Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "\n",
    "def evaluation(y_true, y_pred):\n",
    "    \n",
    "    print('Evaluation Metrics:')\n",
    "    print('Accuracy: ' + str(metrics.accuracy_score(y_true, y_pred)))\n",
    "    print('Precision: ' + str(metrics.precision_score(y_true, y_pred)))\n",
    "    print('Recall: ' + str(metrics.recall_score(y_true, y_pred)))\n",
    "    print('F1 Score: ' + str(metrics.f1_score(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF.\n",
    "\n",
    "I will also create dictionaries for each model so that I will be able to create a DataFrame with the models' results. For better visualization, I will evaluate each model by the end of each section.\n",
    "\n",
    "\n",
    "<b>Note:</b> You will see that I will instantiate the same model multiple times. This will be done so that you can run each model individually, without having the run all the cells for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:59:42.245399Z",
     "start_time": "2020-12-16T20:59:41.775860Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_baseline = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_baseline.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_base_cv = lg_baseline.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:57:29.902286Z",
     "start_time": "2020-12-16T20:57:29.879454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_cv_accuracy = accuracy_score(y_test, y_lg_base_cv)\n",
    "lr_cv_precision = precision_score(y_test, y_lg_base_cv)\n",
    "lr_cv_recall = recall_score(y_test, y_lg_base_cv)\n",
    "lr_cv_f1 = f1_score(y_test, y_lg_base_cv)\n",
    "\n",
    "metric_dict = {}\n",
    "metric_dict['Baseline Logisitic Regression CV'] = {'Accuracy': lr_cv_accuracy,\n",
    "                                                'Precision': lr_cv_precision,\n",
    "                                                'Recall': lr_cv_recall,\n",
    "                                                'F1 Score': lr_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:57:37.895618Z",
     "start_time": "2020-12-16T20:57:37.876018Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.798149861239593\n",
      "Precision: 0.8104575163398693\n",
      "Recall: 0.7968582649053909\n",
      "F1 Score: 0.8036003600360035\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression baseline evaluation\n",
    "evaluation(y_test, y_lg_base_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:59:05.200564Z",
     "start_time": "2020-12-16T20:58:58.980428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_baseline = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_cv = rf_baseline.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:59:05.222260Z",
     "start_time": "2020-12-16T20:59:05.203619Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_cv_accuracy = accuracy_score(y_test, y_rf_cv)\n",
    "rf_cv_precision = precision_score(y_test, y_rf_cv)\n",
    "rf_cv_recall = recall_score(y_test, y_rf_cv)\n",
    "rf_cv_f1 = f1_score(y_test, y_rf_cv)\n",
    "\n",
    "metric_dict['Baseline Random Forest CV'] = {'Accuracy': rf_cv_accuracy,\n",
    "                                                'Precision': rf_cv_precision,\n",
    "                                                'Recall': rf_cv_recall,\n",
    "                                                'F1 Score': rf_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:47:51.566703Z",
     "start_time": "2020-12-16T19:47:51.548666Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7979648473635522\n",
      "Precision: 0.8354927365528072\n",
      "Recall: 0.7597286683327383\n",
      "F1 Score: 0.7958115183246074\n"
     ]
    }
   ],
   "source": [
    "# Random Forest baseline evaluation\n",
    "evaluation(y_test, y_rf_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:01:31.183841Z",
     "start_time": "2020-12-16T21:01:31.172456Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "nb_base_cv = MultinomialNB(alpha = .01)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "nb_base_cv.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_nb_base_cv = nb_base_cv.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:09:05.314737Z",
     "start_time": "2020-12-16T21:09:05.297475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "nb_cv_accuracy = accuracy_score(y_test, y_nb_base_cv)\n",
    "nb_cv_precision = precision_score(y_test, y_nb_base_cv)\n",
    "nb_cv_recall = recall_score(y_test, y_nb_base_cv)\n",
    "nb_cv_f1 = f1_score(y_test, y_nb_base_cv)\n",
    "\n",
    "metric_dict['Baseline Naive Bayes CV'] = {'Accuracy': nb_cv_accuracy,\n",
    "                                                'Precision': nb_cv_precision,\n",
    "                                                'Recall': nb_cv_recall,\n",
    "                                                'F1 Score': nb_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:09:05.811431Z",
     "start_time": "2020-12-16T21:09:05.794423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7811285846438483\n",
      "Precision: 0.7935413642960812\n",
      "Recall: 0.7807925740806855\n",
      "F1 Score: 0.7871153500089977\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes baseline evaluation\n",
    "evaluation(y_test, y_nb_base_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:10:22.756471Z",
     "start_time": "2020-12-16T21:09:07.004104Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc = svc.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:10:22.774854Z",
     "start_time": "2020-12-16T21:10:22.759199Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_cv_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "svc_cv_precision = precision_score(y_test, y_pred_svc)\n",
    "svc_cv_recall = recall_score(y_test, y_pred_svc)\n",
    "svc_cv_f1 = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "metric_dict['Baseline SVC CV'] = {'Accuracy': svc_cv_accuracy,\n",
    "                                  'Precision': svc_cv_precision,\n",
    "                                  'Recall': svc_cv_recall,\n",
    "                                  'F1 Score': svc_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:11:37.130009Z",
     "start_time": "2020-12-16T21:11:37.113347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7839037927844589\n",
      "Precision: 0.7942342342342342\n",
      "Recall: 0.7868618350589075\n",
      "F1 Score: 0.7905308464849354\n"
     ]
    }
   ],
   "source": [
    "# SVC baseline evaluation\n",
    "evaluation(y_test, y_pred_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:10:22.806017Z",
     "start_time": "2020-12-16T21:10:22.795930Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.800740</td>\n",
       "      <td>0.838039</td>\n",
       "      <td>0.762942</td>\n",
       "      <td>0.798729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Logisitic Regression CV  0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest CV         0.800740   0.838039  0.762942  0.798729\n",
       "Baseline Naive Bayes CV           0.781129   0.793541  0.780793  0.787115\n",
       "Baseline SVC CV                   0.783904   0.794234  0.786862  0.790531"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the models performed quite well for baseline models. The three best models were Random Forest, Logistic Regression, and SVC. Naive Bayes did a good job as well, but it under performed if compared to the other models in the accuracy metric, which is my focus for this project.\n",
    "\n",
    "It is interesting to see that Logistic Regression performed in second place between these baseline models. It tells us that although not usually seen as a powerful model, it holds it's surprises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will see how each of the three best models in the previous section performs when using the TF-IDF vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:18:32.935577Z",
     "start_time": "2020-12-16T21:18:32.637638Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_baseline = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_baseline.fit(X_train_tfidf, y_train) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_base_tfidf = lg_baseline.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:18:34.645105Z",
     "start_time": "2020-12-16T21:18:34.628212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lg_tfidf_accuracy = accuracy_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_precision = precision_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_recall = recall_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_f1 = f1_score(y_test, y_lg_base_tfidf)\n",
    "\n",
    "metric_dict['Baseline Logistic Regression TF-IDF'] = {'Accuracy': lg_tfidf_accuracy,\n",
    "                                                'Precision': lg_tfidf_precision,\n",
    "                                                'Recall': lg_tfidf_recall,\n",
    "                                                'F1 Score': lg_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:18:38.188854Z",
     "start_time": "2020-12-16T21:18:38.171963Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8170212765957446\n",
      "Precision: 0.8481936971560338\n",
      "Recall: 0.7879328811138879\n",
      "F1 Score: 0.8169535443272257\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_lg_base_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:19:24.749277Z",
     "start_time": "2020-12-16T21:19:02.350264Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "rf_baseline = RandomForestClassifier()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_base_tfidf = rf_baseline.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:19:24.770713Z",
     "start_time": "2020-12-16T21:19:24.751655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_tfidf_accuracy = accuracy_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_precision = precision_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_recall = recall_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_f1 = f1_score(y_test, y_rf_base_tfidf)\n",
    "\n",
    "metric_dict['Baseline Random Forest TF-IDF'] = {'Accuracy': rf_tfidf_accuracy,\n",
    "                                                'Precision': rf_tfidf_precision,\n",
    "                                                'Recall': rf_tfidf_recall,\n",
    "                                                'F1 Score': rf_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T21:19:24.791995Z",
     "start_time": "2020-12-16T21:19:24.774027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.801295097132285\n",
      "Precision: 0.8409001184366364\n",
      "Recall: 0.7604426990360585\n",
      "F1 Score: 0.7986501687289089\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_rf_base_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T16:43:18.063837Z",
     "start_time": "2020-12-15T16:43:18.061209Z"
    }
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-16T21:19:13.876Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='rbf')\n",
    "svc.fit(X_train_tfidf, y_train)\n",
    "y_pred_svc_tfidf = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-16T21:19:14.933Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_tfidf_accuracy = accuracy_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_precision = precision_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_recall = recall_score(y_test, y_pred_svc_tfidf)\n",
    "svc_tfidf_f1 = f1_score(y_test, y_pred_svc_tfidf)\n",
    "\n",
    "metric_dict['Baseline SVC TF-IDF'] = {'Accuracy': svc_tfidf_accuracy,\n",
    "                                                'Precision': svc_tfidf_precision,\n",
    "                                                'Recall': svc_tfidf_recall,\n",
    "                                                'F1 Score': svc_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-16T21:19:15.720Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluation(y_test, y_pred_svc_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-16T21:19:18.454Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF With Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:09.160428Z",
     "start_time": "2020-12-16T19:52:08.840773Z"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline Regression Model\n",
    "rf_baseline = LogisticRegression(random_state=1)\n",
    "rf_baseline.fit(X_train_lem, y_train_lem) \n",
    "y_lg_base_tfidf_lem = rf_baseline.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:09.184376Z",
     "start_time": "2020-12-16T19:52:09.162996Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_lem_accuracy = accuracy_score(y_test_lem, y_lg_base_tfidf_lem)\n",
    "lr_lem_precision = precision_score(y_test_lem, y_lg_base_tfidf_lem)\n",
    "lr_lem_recall = recall_score(y_test_lem, y_lg_base_tfidf_lem)\n",
    "lr_lem_f1 = f1_score(y_test_lem, y_lg_base_tfidf_lem)\n",
    "\n",
    "metric_dict['Baseline Logistic Regression Lem'] = {'Accuracy': lr_lem_accuracy,\n",
    "                                                'Precision': lr_lem_precision,\n",
    "                                                'Recall': lr_lem_recall,\n",
    "                                                'F1 Score': lr_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:09.209533Z",
     "start_time": "2020-12-16T19:52:09.186983Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8177613320999075\n",
      "Precision: 0.8314990512333966\n",
      "Recall: 0.8019765739385066\n",
      "F1 Score: 0.8164710266443078\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_lg_base_tfidf_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:28.708785Z",
     "start_time": "2020-12-16T19:52:09.212154Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_baseline = RandomForestClassifier(random_state=1)\n",
    "rf_baseline.fit(X_train_lem, y_train_lem) \n",
    "y_rf_base_lem = rf_baseline.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:28.726383Z",
     "start_time": "2020-12-16T19:52:28.710868Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_lem_accuracy = accuracy_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_precision = precision_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_recall = recall_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_f1 = f1_score(y_test_lem, y_rf_base_lem)\n",
    "\n",
    "metric_dict['Baseline Random Forest Lem'] = {'Accuracy': rf_lem_accuracy,\n",
    "                                                'Precision': rf_lem_precision,\n",
    "                                                'Recall': rf_lem_recall,\n",
    "                                                'F1 Score': rf_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:52:28.744826Z",
     "start_time": "2020-12-16T19:52:28.728354Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.4967622571692877\n",
      "Precision: 0.5023715415019763\n",
      "Recall: 0.4652269399707174\n",
      "F1 Score: 0.48308627898137585\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_rf_base_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:07.740509Z",
     "start_time": "2020-12-16T19:52:28.747132Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_lem, y_train_lem)\n",
    "y_pred_svc_lem = svc.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:07.767734Z",
     "start_time": "2020-12-16T19:53:07.742978Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_lem_accuracy = accuracy_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_precision = precision_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_recall = recall_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_f1 = f1_score(y_test_lem, y_pred_svc_lem)\n",
    "\n",
    "metric_dict['Baseline Random Forest Lem'] = {'Accuracy': svc_lem_accuracy,\n",
    "                                                'Precision': svc_lem_precision,\n",
    "                                                'Recall': svc_lem_recall,\n",
    "                                                'F1 Score': svc_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:07.793015Z",
     "start_time": "2020-12-16T19:53:07.770315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8144310823311748\n",
      "Precision: 0.8303400840657241\n",
      "Recall: 0.7953879941434846\n",
      "F1 Score: 0.8124883155730044\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test_lem, y_pred_svc_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:07.811845Z",
     "start_time": "2020-12-16T19:53:07.795735Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.797965</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.759729</td>\n",
       "      <td>0.795812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>0.792574</td>\n",
       "      <td>0.822375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.802220</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.799475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.826827</td>\n",
       "      <td>0.867271</td>\n",
       "      <td>0.786148</td>\n",
       "      <td>0.824719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.830340</td>\n",
       "      <td>0.795388</td>\n",
       "      <td>0.812488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest CV            0.797965   0.835493  0.759729  0.795812\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.803600\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Logistic Regression TF-IDF  0.822572   0.854503  0.792574  0.822375\n",
       "Baseline Random Forest TF-IDF        0.802220   0.842292  0.760800  0.799475\n",
       "Baseline SVC TF-IDF                  0.826827   0.867271  0.786148  0.824719\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Random Forest Lem           0.814431   0.830340  0.795388  0.812488"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:12.394256Z",
     "start_time": "2020-12-16T19:53:07.814809Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_smote_tfidf, y_train_smote_tfidf = smote.fit_sample(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:37.891041Z",
     "start_time": "2020-12-16T19:53:12.397308Z"
    }
   },
   "outputs": [],
   "source": [
    "rf_base_tfidf = RandomForestClassifier(random_state=1)\n",
    "rf_base_tfidf.fit(X_train_smote_tfidf, y_train_smote_tfidf)\n",
    "y_rf_base_tfidf_smote = rf_base_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:37.911416Z",
     "start_time": "2020-12-16T19:53:37.893292Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_smote_accuracy = accuracy_score(y_test, y_rf_base_tfidf_smote)\n",
    "rf_smote_precision = precision_score(y_test, y_rf_base_tfidf_smote)\n",
    "rf_smote_recall = recall_score(y_test, y_rf_base_tfidf_smote)\n",
    "rf_smote_f1 = f1_score(y_test, y_rf_base_tfidf_smote)\n",
    "\n",
    "metric_dict['Baseline Random Forest SMOTE'] = {'Accuracy': rf_smote_accuracy,\n",
    "                                                'Precision': rf_smote_precision,\n",
    "                                                'Recall': rf_smote_recall,\n",
    "                                                'F1 Score': rf_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:53:37.929954Z",
     "start_time": "2020-12-16T19:53:37.913415Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7990749306197965\n",
      "Precision: 0.848435595286469\n",
      "Recall: 0.7454480542663334\n",
      "F1 Score: 0.7936145952109463\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_rf_base_tfidf_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:40:32.733033Z",
     "start_time": "2020-12-16T19:40:32.730826Z"
    }
   },
   "source": [
    "## SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.513777Z",
     "start_time": "2020-12-16T19:53:37.932133Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_smote_tfidf, y_train_smote_tfidf)\n",
    "y_pred_svc_smote = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.531719Z",
     "start_time": "2020-12-16T19:54:36.515918Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_smote_accuracy = accuracy_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_precision = precision_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_recall = recall_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_f1 = f1_score(y_test, y_pred_svc_smote)\n",
    "\n",
    "metric_dict['Baseline SVC SMOTE'] = {'Accuracy': svc_smote_accuracy,\n",
    "                                                'Precision': svc_smote_precision,\n",
    "                                                'Recall': svc_smote_recall,\n",
    "                                                'F1 Score': svc_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.550059Z",
     "start_time": "2020-12-16T19:54:36.533458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8155411655874191\n",
      "Precision: 0.8528951486697965\n",
      "Recall: 0.7782934666190646\n",
      "F1 Score: 0.8138883703565429\n"
     ]
    }
   ],
   "source": [
    "evaluation(y_test, y_pred_svc_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.563720Z",
     "start_time": "2020-12-16T19:54:36.552410Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.797965</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.759729</td>\n",
       "      <td>0.795812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>0.792574</td>\n",
       "      <td>0.822375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.802220</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.799475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.826827</td>\n",
       "      <td>0.867271</td>\n",
       "      <td>0.786148</td>\n",
       "      <td>0.824719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.830340</td>\n",
       "      <td>0.795388</td>\n",
       "      <td>0.812488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.799075</td>\n",
       "      <td>0.848436</td>\n",
       "      <td>0.745448</td>\n",
       "      <td>0.793615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.815541</td>\n",
       "      <td>0.852895</td>\n",
       "      <td>0.778293</td>\n",
       "      <td>0.813888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest CV            0.797965   0.835493  0.759729  0.795812\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.803600\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Logistic Regression TF-IDF  0.822572   0.854503  0.792574  0.822375\n",
       "Baseline Random Forest TF-IDF        0.802220   0.842292  0.760800  0.799475\n",
       "Baseline SVC TF-IDF                  0.826827   0.867271  0.786148  0.824719\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Random Forest Lem           0.814431   0.830340  0.795388  0.812488\n",
       "Baseline Random Forest SMOTE         0.799075   0.848436  0.745448  0.793615\n",
       "Baseline SVC SMOTE                   0.815541   0.852895  0.778293  0.813888"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:47:12.077415Z",
     "start_time": "2020-12-16T19:47:12.075016Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.577225Z",
     "start_time": "2020-12-16T19:54:36.565977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest CV</th>\n",
       "      <td>0.797965</td>\n",
       "      <td>0.835493</td>\n",
       "      <td>0.759729</td>\n",
       "      <td>0.795812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression TF-IDF</th>\n",
       "      <td>0.822572</td>\n",
       "      <td>0.854503</td>\n",
       "      <td>0.792574</td>\n",
       "      <td>0.822375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest TF-IDF</th>\n",
       "      <td>0.802220</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>0.760800</td>\n",
       "      <td>0.799475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC TF-IDF</th>\n",
       "      <td>0.826827</td>\n",
       "      <td>0.867271</td>\n",
       "      <td>0.786148</td>\n",
       "      <td>0.824719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Logistic Regression Lem</th>\n",
       "      <td>0.817761</td>\n",
       "      <td>0.831499</td>\n",
       "      <td>0.801977</td>\n",
       "      <td>0.816471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest Lem</th>\n",
       "      <td>0.814431</td>\n",
       "      <td>0.830340</td>\n",
       "      <td>0.795388</td>\n",
       "      <td>0.812488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline Random Forest SMOTE</th>\n",
       "      <td>0.799075</td>\n",
       "      <td>0.848436</td>\n",
       "      <td>0.745448</td>\n",
       "      <td>0.793615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline SVC SMOTE</th>\n",
       "      <td>0.815541</td>\n",
       "      <td>0.852895</td>\n",
       "      <td>0.778293</td>\n",
       "      <td>0.813888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Accuracy  Precision    Recall  F1 Score\n",
       "Baseline Logisitic Regression CV     0.798150   0.810458  0.796858  0.803600\n",
       "Baseline Random Forest CV            0.797965   0.835493  0.759729  0.795812\n",
       "Baseline Naive Bayes CV              0.781129   0.793541  0.780793  0.803600\n",
       "Baseline SVC CV                      0.783904   0.794234  0.786862  0.790531\n",
       "Baseline Logistic Regression TF-IDF  0.822572   0.854503  0.792574  0.822375\n",
       "Baseline Random Forest TF-IDF        0.802220   0.842292  0.760800  0.799475\n",
       "Baseline SVC TF-IDF                  0.826827   0.867271  0.786148  0.824719\n",
       "Baseline Logistic Regression Lem     0.817761   0.831499  0.801977  0.816471\n",
       "Baseline Random Forest Lem           0.814431   0.830340  0.795388  0.812488\n",
       "Baseline Random Forest SMOTE         0.799075   0.848436  0.745448  0.793615\n",
       "Baseline SVC SMOTE                   0.815541   0.852895  0.778293  0.813888"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(metric_dict, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(y_test, SVM_test_preds)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Hate Speech', 'Not Hate Speech'], yticklabels=['Hate Speech', 'Not Hate Speech'], cmap=\"Blues\")\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "plt.title('Naive Bayes Baseline')\n",
    "\n",
    "# fixing matplotlib heatmap cutoff issue\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Train Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.597995Z",
     "start_time": "2020-12-16T19:54:36.579554Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_train_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.608582Z",
     "start_time": "2020-12-16T19:54:36.600459Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_test_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:54:36.619459Z",
     "start_time": "2020-12-16T19:54:36.610650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train and Test Set = Target\n",
    "y_train.to_pickle(\"../pickle/y_train.pkl\")\n",
    "y_test.to_pickle(\"../pickle/y_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
