{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will find the baseline models, also known as vanilla models. For the baseline models, I will run Logistic Regression, which is a basic but reliable model - it works well with binary classification?; Random Forest because I believe a Decision Tree could bring me good results but since Random Forest is a collection of Decision Trees, I can skip it and start with Random Forest; Naive Bayes, which is know for giving good results when applied to NLP; and Support Vector Machine, which is also known for working well with Natural Language Processing.\n",
    "\n",
    "I will try the vanilla models with the datasets vectorized with CountVectorizer, TF-IDF. I will try these models with and without lemmatization. I will also iterate the best models with a train set using SMOTE. I have fixed the class imbalance manually in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/preprossessing/data-cleaning.ipynb\">Data Cleaning</a> notebook. However, I'm curious to see if the models could have any improvement with SMOTE. I will use the `Spell_Checked` feature, since it's the cleanest one. I will not include other features from the original data set because the main objective is train a model using the reviews only.\n",
    "\n",
    "I have a binary classification, where the target will be 0 for negative review and 1 for positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprossess the dataset creating train and test datasets\n",
    "- Run models for each vectorizer used\n",
    "- Find the best models for each category\n",
    "- Evaluate Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import important packages and the data set we will use, which was already cleaned in the Data Cleaning notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:48.679952Z",
     "start_time": "2021-01-04T18:13:48.648985Z"
    }
   },
   "outputs": [],
   "source": [
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# NLP Packages\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# WordCloud\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# Sklearn Packages\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import text \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, plot_confusion_matrix, roc_curve, auc, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.display import display, HTML\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Pandas Settings\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "# Solve warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# Import pickle and ELI5\n",
    "import pickle\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:49.226279Z",
     "start_time": "2021-01-04T18:13:49.223431Z"
    }
   },
   "outputs": [],
   "source": [
    "from functions import evaluation\n",
    "from functions import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the main dataset and the lemmatized X and y variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:51.992114Z",
     "start_time": "2021-01-04T18:13:51.696344Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing cleaned dataset as a DataFrame\n",
    "df = pd.read_csv('../csv/Hotel_Review_Spell_Checked.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:53.034612Z",
     "start_time": "2021-01-04T18:13:53.014783Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Hotel_Name</th>\n",
       "      <th>Negative_Review</th>\n",
       "      <th>Positive_Review</th>\n",
       "      <th>Reviewer_Score</th>\n",
       "      <th>Reviews_Clean</th>\n",
       "      <th>Score</th>\n",
       "      <th>Spell_Checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>185010</td>\n",
       "      <td>St James Court A Taj Hotel London</td>\n",
       "      <td>No Negative</td>\n",
       "      <td>the location was perfect</td>\n",
       "      <td>9.6</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "      <td>1</td>\n",
       "      <td>no negative the location was perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>424531</td>\n",
       "      <td>H10 Metropolitan 4 Sup</td>\n",
       "      <td>Nothing</td>\n",
       "      <td>Everything was top notch staff were impeccable</td>\n",
       "      <td>10.0</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "      <td>1</td>\n",
       "      <td>nothing  everything was top notch staff were ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1                         Hotel_Name Negative_Review  \\\n",
       "0        185010  St James Court A Taj Hotel London     No Negative   \n",
       "1        424531             H10 Metropolitan 4 Sup        Nothing    \n",
       "\n",
       "                                    Positive_Review  Reviewer_Score  \\\n",
       "0                         the location was perfect              9.6   \n",
       "1   Everything was top notch staff were impeccable             10.0   \n",
       "\n",
       "                                       Reviews_Clean  Score  \\\n",
       "0              no negative the location was perfect       1   \n",
       "1   nothing  everything was top notch staff were ...      1   \n",
       "\n",
       "                                       Spell_Checked  \n",
       "0              no negative the location was perfect   \n",
       "1   nothing  everything was top notch staff were ...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking DataFrame\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Lemmatized X and Y Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I lemmatized the feature variable `Spell_Checked` in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/preprossessing/data-cleaning.ipynb\">Data Cleaning</a> notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:55.905454Z",
     "start_time": "2021-01-04T18:13:55.872071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing lemmatized X and y variable\n",
    "X_lem = pickle.load(open('../pickle/X_lem.pkl', 'rb'))\n",
    "y_lem = pd.read_pickle('../pickle/y_lem.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:56.479498Z",
     "start_time": "2021-01-04T18:13:56.469323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing stop_words\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:56.831979Z",
     "start_time": "2021-01-04T18:13:56.813080Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping null values, if any\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned in the introduction, I will use the column `Spell_Checked` to create the features and `Score` as my target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:59.621413Z",
     "start_time": "2021-01-04T18:13:59.589780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating an X variable and y for my target\n",
    "X = df.Spell_Checked\n",
    "y = df.Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:13:59.977248Z",
     "start_time": "2021-01-04T18:13:59.968136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset in train set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split with Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:14:01.149777Z",
     "start_time": "2021-01-04T18:14:01.134965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the lemmatized dataset in train set and test set\n",
    "X_train_lem, X_test_lem, y_train_lem, y_test_lem = train_test_split(X_lem, y_lem, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:14:03.329200Z",
     "start_time": "2021-01-04T18:14:02.474715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cv = CountVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fitting into the train and test set\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:14:08.338915Z",
     "start_time": "2021-01-04T18:14:07.581646Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate TF-IDF Vectorizer\n",
    "tfidf = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Fitting into the train and test set\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:14:17.743976Z",
     "start_time": "2021-01-04T18:14:08.738853Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert TF-IDF Vector back to a dataframe so I can get feature importance later\n",
    "X_train_tfidf_sparse = pd.DataFrame.sparse.from_spmatrix(\n",
    "    X_train_tfidf, columns=tfidf.get_feature_names())\n",
    "X_test_tfidf_sparse = pd.DataFrame.sparse.from_spmatrix(\n",
    "    X_test_tfidf, columns=tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:19:23.602080Z",
     "start_time": "2021-01-04T18:19:23.599310Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_tfidf = X_train_tfidf_sparse\n",
    "X_test_tfidf = X_test_tfidf_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:19:25.517686Z",
     "start_time": "2021-01-04T18:19:25.196425Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aback</th>\n",
       "      <th>abadoneded</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abbey</th>\n",
       "      <th>abdicated</th>\n",
       "      <th>abduction</th>\n",
       "      <th>abdulrahim</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abroad</th>\n",
       "      <th>abrupt</th>\n",
       "      <th>abruptly</th>\n",
       "      <th>absence</th>\n",
       "      <th>absent</th>\n",
       "      <th>absolute</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>absorb</th>\n",
       "      <th>absurd</th>\n",
       "      <th>abundance</th>\n",
       "      <th>abundant</th>\n",
       "      <th>abused</th>\n",
       "      <th>abusive</th>\n",
       "      <th>abusmal</th>\n",
       "      <th>abysmal</th>\n",
       "      <th>abysmally</th>\n",
       "      <th>ac</th>\n",
       "      <th>accent</th>\n",
       "      <th>accentuating</th>\n",
       "      <th>accept</th>\n",
       "      <th>acceptable</th>\n",
       "      <th>accepted</th>\n",
       "      <th>accepting</th>\n",
       "      <th>accesories</th>\n",
       "      <th>access</th>\n",
       "      <th>accessability</th>\n",
       "      <th>accessed</th>\n",
       "      <th>accessibilty</th>\n",
       "      <th>accessible</th>\n",
       "      <th>accessories</th>\n",
       "      <th>accident</th>\n",
       "      <th>accidental</th>\n",
       "      <th>accidentally</th>\n",
       "      <th>accidently</th>\n",
       "      <th>accomadating</th>\n",
       "      <th>accomendating</th>\n",
       "      <th>accommodate</th>\n",
       "      <th>accommodated</th>\n",
       "      <th>accommodation</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrongly</th>\n",
       "      <th>wrote</th>\n",
       "      <th>wrung</th>\n",
       "      <th>www</th>\n",
       "      <th>wyndham</th>\n",
       "      <th>xingxia</th>\n",
       "      <th>xx</th>\n",
       "      <th>xxx</th>\n",
       "      <th>xxxi</th>\n",
       "      <th>yard</th>\n",
       "      <th>yards</th>\n",
       "      <th>yazeem</th>\n",
       "      <th>ye</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>years</th>\n",
       "      <th>yell</th>\n",
       "      <th>yelled</th>\n",
       "      <th>yelling</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yellowing</th>\n",
       "      <th>yep</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yet</th>\n",
       "      <th>yield</th>\n",
       "      <th>yielded</th>\n",
       "      <th>yipeeee</th>\n",
       "      <th>yoghurt</th>\n",
       "      <th>yoghurts</th>\n",
       "      <th>york</th>\n",
       "      <th>yougurt</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngest</th>\n",
       "      <th>youngsters</th>\n",
       "      <th>yourdoorstep</th>\n",
       "      <th>youth</th>\n",
       "      <th>youths</th>\n",
       "      <th>yukkkkno</th>\n",
       "      <th>yuri</th>\n",
       "      <th>zafirovski</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zenith</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeus</th>\n",
       "      <th>zoitan</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16209</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16210</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16211</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16212</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16213</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16214 rows × 10780 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aback  abadoneded  abandon  abandoned  abbey  abdicated  abduction  \\\n",
       "0        0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "1        0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "2        0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "3        0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "4        0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "...      ...         ...      ...        ...    ...        ...        ...   \n",
       "16209    0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "16210    0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "16211    0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "16212    0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "16213    0.0         0.0      0.0        0.0    0.0        0.0        0.0   \n",
       "\n",
       "       abdulrahim  ability     able  abnormal  abroad  abrupt  abruptly  \\\n",
       "0             0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "1             0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "2             0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "3             0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "4             0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "...           ...      ...      ...       ...     ...     ...       ...   \n",
       "16209         0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "16210         0.0      0.0  0.16101       0.0     0.0     0.0       0.0   \n",
       "16211         0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "16212         0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "16213         0.0      0.0  0.00000       0.0     0.0     0.0       0.0   \n",
       "\n",
       "       absence  absent  absolute  absolutely  absorb  absurd  abundance  \\\n",
       "0          0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "1          0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "2          0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "3          0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "4          0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "...        ...     ...       ...         ...     ...     ...        ...   \n",
       "16209      0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "16210      0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "16211      0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "16212      0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "16213      0.0     0.0       0.0         0.0     0.0     0.0        0.0   \n",
       "\n",
       "       abundant  abused  abusive  abusmal  abysmal  abysmally   ac  accent  \\\n",
       "0           0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "1           0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "2           0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "3           0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "4           0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "...         ...     ...      ...      ...      ...        ...  ...     ...   \n",
       "16209       0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "16210       0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "16211       0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "16212       0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "16213       0.0     0.0      0.0      0.0      0.0        0.0  0.0     0.0   \n",
       "\n",
       "       accentuating  accept  acceptable  accepted  accepting  accesories  \\\n",
       "0               0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "1               0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "2               0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "3               0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "4               0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "...             ...     ...         ...       ...        ...         ...   \n",
       "16209           0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "16210           0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "16211           0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "16212           0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "16213           0.0     0.0         0.0       0.0        0.0         0.0   \n",
       "\n",
       "       access  accessability  accessed  accessibilty  accessible  accessories  \\\n",
       "0         0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "1         0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "2         0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "3         0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "4         0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "...       ...            ...       ...           ...         ...          ...   \n",
       "16209     0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "16210     0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "16211     0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "16212     0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "16213     0.0            0.0       0.0           0.0         0.0          0.0   \n",
       "\n",
       "       accident  accidental  accidentally  accidently  accomadating  \\\n",
       "0           0.0         0.0           0.0         0.0           0.0   \n",
       "1           0.0         0.0           0.0         0.0           0.0   \n",
       "2           0.0         0.0           0.0         0.0           0.0   \n",
       "3           0.0         0.0           0.0         0.0           0.0   \n",
       "4           0.0         0.0           0.0         0.0           0.0   \n",
       "...         ...         ...           ...         ...           ...   \n",
       "16209       0.0         0.0           0.0         0.0           0.0   \n",
       "16210       0.0         0.0           0.0         0.0           0.0   \n",
       "16211       0.0         0.0           0.0         0.0           0.0   \n",
       "16212       0.0         0.0           0.0         0.0           0.0   \n",
       "16213       0.0         0.0           0.0         0.0           0.0   \n",
       "\n",
       "       accomendating  accommodate  accommodated  accommodation  ...  wrong  \\\n",
       "0                0.0          0.0           0.0            0.0  ...    0.0   \n",
       "1                0.0          0.0           0.0            0.0  ...    0.0   \n",
       "2                0.0          0.0           0.0            0.0  ...    0.0   \n",
       "3                0.0          0.0           0.0            0.0  ...    0.0   \n",
       "4                0.0          0.0           0.0            0.0  ...    0.0   \n",
       "...              ...          ...           ...            ...  ...    ...   \n",
       "16209            0.0          0.0           0.0            0.0  ...    0.0   \n",
       "16210            0.0          0.0           0.0            0.0  ...    0.0   \n",
       "16211            0.0          0.0           0.0            0.0  ...    0.0   \n",
       "16212            0.0          0.0           0.0            0.0  ...    0.0   \n",
       "16213            0.0          0.0           0.0            0.0  ...    0.0   \n",
       "\n",
       "       wrongly  wrote  wrung  www  wyndham  xingxia   xx  xxx  xxxi  yard  \\\n",
       "0          0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "1          0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "2          0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "3          0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "4          0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "...        ...    ...    ...  ...      ...      ...  ...  ...   ...   ...   \n",
       "16209      0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "16210      0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "16211      0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "16212      0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "16213      0.0    0.0    0.0  0.0      0.0      0.0  0.0  0.0   0.0   0.0   \n",
       "\n",
       "       yards  yazeem   ye  yeah  year  yearly  years  yell  yelled  yelling  \\\n",
       "0        0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "1        0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "2        0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "3        0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "4        0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "...      ...     ...  ...   ...   ...     ...    ...   ...     ...      ...   \n",
       "16209    0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "16210    0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "16211    0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "16212    0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "16213    0.0     0.0  0.0   0.0   0.0     0.0    0.0   0.0     0.0      0.0   \n",
       "\n",
       "       yellow  yellowing  yep  yes  yesterday  yet  yield  yielded  yipeeee  \\\n",
       "0         0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "1         0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "2         0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "3         0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "4         0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "...       ...        ...  ...  ...        ...  ...    ...      ...      ...   \n",
       "16209     0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "16210     0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "16211     0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "16212     0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "16213     0.0        0.0  0.0  0.0        0.0  0.0    0.0      0.0      0.0   \n",
       "\n",
       "       yoghurt  yoghurts  york  yougurt  young  younger  youngest  youngsters  \\\n",
       "0          0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "1          0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "2          0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "3          0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "4          0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "...        ...       ...   ...      ...    ...      ...       ...         ...   \n",
       "16209      0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "16210      0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "16211      0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "16212      0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "16213      0.0       0.0   0.0      0.0    0.0      0.0       0.0         0.0   \n",
       "\n",
       "       yourdoorstep  youth  youths  yukkkkno  yuri  zafirovski  zealand  \\\n",
       "0               0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "1               0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "2               0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "3               0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "4               0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "...             ...    ...     ...       ...   ...         ...      ...   \n",
       "16209           0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "16210           0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "16211           0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "16212           0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "16213           0.0    0.0     0.0       0.0   0.0         0.0      0.0   \n",
       "\n",
       "       zenith  zero  zeus  zoitan  zone  \n",
       "0         0.0   0.0   0.0     0.0   0.0  \n",
       "1         0.0   0.0   0.0     0.0   0.0  \n",
       "2         0.0   0.0   0.0     0.0   0.0  \n",
       "3         0.0   0.0   0.0     0.0   0.0  \n",
       "4         0.0   0.0   0.0     0.0   0.0  \n",
       "...       ...   ...   ...     ...   ...  \n",
       "16209     0.0   0.0   0.0     0.0   0.0  \n",
       "16210     0.0   0.0   0.0     0.0   0.0  \n",
       "16211     0.0   0.0   0.0     0.0   0.0  \n",
       "16212     0.0   0.0   0.0     0.0   0.0  \n",
       "16213     0.0   0.0   0.0     0.0   0.0  \n",
       "\n",
       "[16214 rows x 10780 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-DF With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:18:10.831480Z",
     "start_time": "2021-01-04T16:18:10.212691Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fitting into the lemmatized train and test set\n",
    "X_train_lem = tfidf.fit_transform(X_train_lem)\n",
    "X_test_lem = tfidf.transform(X_test_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My main focus is the accuracy metric. Have an accurate is important to be accurate. However, although fixing False Negatives is not crucial, I will also take a look at Recall and F1-Score to understand how my model is working. Since it is not my main focus, I will not mentioned in the individual analysis on my models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF.\n",
    "\n",
    "I will also create dictionaries for each model so that I will be able to create a DataFrame with the models' results. For better visualization, I will evaluate each model by the end of each section.\n",
    "\n",
    "\n",
    "<b>Note:</b> You will see that I will instantiate the same model multiple times. This will be done so that you can run each model individually, without having the run all the cells for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling With Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will run the Logistic Regression, Random Forest, Naive Bayes, and SVC models for the dataset that was vectorized using Count Vectorizer. Then, I will pick the three best models and move to the next section, which will be using TF-IDF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:15:21.015267Z",
     "start_time": "2021-01-04T18:15:20.477973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_cv = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_cv.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_cv = lg_cv.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:15:01.334958Z",
     "start_time": "2021-01-04T18:15:01.121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_cv_accuracy = accuracy_score(y_test, y_lg_cv)\n",
    "lr_cv_precision = precision_score(y_test, y_lg_cv)\n",
    "lr_cv_recall = recall_score(y_test, y_lg_cv)\n",
    "lr_cv_f1 = f1_score(y_test, y_lg_cv)\n",
    "\n",
    "metric_dict = {}\n",
    "metric_dict['Vanilla Logisitic Regression CV'] = {'Accuracy': lr_cv_accuracy,\n",
    "                                                'Precision': lr_cv_precision,\n",
    "                                                'Recall': lr_cv_recall,\n",
    "                                                'F1 Score': lr_cv_f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:18:15.504568Z",
     "start_time": "2021-01-04T16:18:13.390913Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.798149861239593\n",
      "Precision: 0.8104575163398693\n",
      "Recall: 0.7968582649053909\n",
      "F1 Score: 0.8036003600360035\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.80758557 0.80049337 0.80080173 0.80727721 0.81431215]\n",
      "Min:  0.800493\n",
      "Max:  0.814312\n",
      "Mean:  0.806094\n",
      "Range:  0.013819\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression baseline evaluation\n",
    "evaluation(y_test, y_lg_cv)\n",
    "cross_validation(lg_cv, X_train_cv, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:18:15.526996Z",
     "start_time": "2021-01-04T16:18:15.507693Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vanilla Logisitic Regression CV</th>\n",
       "      <td>0.79815</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.8036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy  Precision    Recall  F1 Score\n",
       "Vanilla Logisitic Regression CV   0.79815   0.810458  0.796858    0.8036"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:30:51.420283Z",
     "start_time": "2021-01-04T16:30:51.399733Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.79      0.80      0.79      2604\n",
      "           0       0.81      0.80      0.80      2801\n",
      "\n",
      "    accuracy                           0.80      5405\n",
      "   macro avg       0.80      0.80      0.80      5405\n",
      "weighted avg       0.80      0.80      0.80      5405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = y_test.unique().astype(str)\n",
    "print(classification_report(y_test, y_lg_cv, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T16:18:20.662274Z",
     "start_time": "2021-01-04T16:18:19.779639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a confusion matrix\n",
    "plt.figure(figsize=(6, 7))\n",
    "mat = confusion_matrix(y_test, y_lg_cv)\n",
    "\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Positive', 'Negative'], yticklabels=['Positive', 'Negative'], cmap=\"Blues\")\n",
    "plt.xlabel('True Label', fontsize= 18)\n",
    "plt.ylabel('Predicted Label', fontsize= 18)\n",
    "plt.title('Baseline Logistic Regression Confusion Matrix', fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "b, t = plt.ylim() \n",
    "t -= 0.05 \n",
    "plt.ylim(b, t) \n",
    "plt.savefig('../images/confusion-matrix-baseline-lg-model.png', bbox_inches = \"tight\", pad_inches=.5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first model, Logistic Regression performed quite well with an accuracy of 0.7981. My main metric is accuracy and it seems that Logistic Regression is able to correctly understand the positive and negative reviews. Looking at the cross validations, it seems that the train set performs similar to the test set with a small difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:12:10.363886Z",
     "start_time": "2021-01-04T18:12:03.522015Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_baseline = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_cv = rf_baseline.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:02:47.682762Z",
     "start_time": "2020-12-24T19:02:47.663238Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_cv_accuracy = accuracy_score(y_test, y_rf_cv)\n",
    "rf_cv_precision = precision_score(y_test, y_rf_cv)\n",
    "rf_cv_recall = recall_score(y_test, y_rf_cv)\n",
    "rf_cv_f1 = f1_score(y_test, y_rf_cv)\n",
    "\n",
    "metric_dict['Vanilla Random Forest CV'] = {'Accuracy': rf_cv_accuracy,\n",
    "                                                'Precision': rf_cv_precision,\n",
    "                                                'Recall': rf_cv_recall,\n",
    "                                                'F1 Score': rf_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:12:41.842227Z",
     "start_time": "2021-01-04T18:12:10.366649Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.798149861239593\n",
      "Precision: 0.8104575163398693\n",
      "Recall: 0.7968582649053909\n",
      "F1 Score: 0.8036003600360035\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.80141844 0.80635214 0.7924761  0.81005242 0.81492906]\n",
      "Min:  0.792476\n",
      "Max:  0.814929\n",
      "Mean:  0.805046\n",
      "Range:  0.022453\n"
     ]
    }
   ],
   "source": [
    "# Random Forest baseline evaluation\n",
    "evaluation(y_test, y_lg_cv)\n",
    "cross_validation(rf_baseline, X_train_cv, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T20:17:00.306528Z",
     "start_time": "2021-01-04T20:16:59.527413Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0399\n",
       "                \n",
       "                    &plusmn; 0.0547\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                negative\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.22%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0210\n",
       "                \n",
       "                    &plusmn; 0.0304\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                positive\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.28%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0164\n",
       "                \n",
       "                    &plusmn; 0.0201\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                excellent\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.31%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0163\n",
       "                \n",
       "                    &plusmn; 0.0201\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                great\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.04%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0127\n",
       "                \n",
       "                    &plusmn; 0.0114\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                room\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 91.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0111\n",
       "                \n",
       "                    &plusmn; 0.0131\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                poor\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.54%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0097\n",
       "                \n",
       "                    &plusmn; 0.0135\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                dirty\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.80%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0093\n",
       "                \n",
       "                    &plusmn; 0.0115\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                comfortable\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 92.86%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0092\n",
       "                \n",
       "                    &plusmn; 0.0135\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                friendly\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0080\n",
       "                \n",
       "                    &plusmn; 0.0051\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                staff\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.79%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0075\n",
       "                \n",
       "                    &plusmn; 0.0115\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                lovely\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 93.83%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0074\n",
       "                \n",
       "                    &plusmn; 0.0084\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                bad\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.16%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0069\n",
       "                \n",
       "                    &plusmn; 0.0026\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                location\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0068\n",
       "                \n",
       "                    &plusmn; 0.0089\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                helpful\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.19%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0068\n",
       "                \n",
       "                    &plusmn; 0.0050\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                small\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.56%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0038\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                hotel\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.58%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0069\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                rude\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.59%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0062\n",
       "                \n",
       "                    &plusmn; 0.0043\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                nice\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.60%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0061\n",
       "                \n",
       "                    &plusmn; 0.0025\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                good\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0058\n",
       "                \n",
       "                    &plusmn; 0.0027\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                breakfast\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.82%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 10760 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='RandomForestClassifier(n_jobs=-1)', description='\\nRandom forest feature importances; values are numbers 0 <= x <= 1;\\nall values sum to 1.\\n', error=None, method='feature importances', is_regression=False, targets=None, feature_importances=FeatureImportances(importances=[FeatureWeight(feature='negative', weight=0.03988034513361218, std=0.027331758519790996, value=None), FeatureWeight(feature='positive', weight=0.021023530653878682, std=0.015203007766515215, value=None), FeatureWeight(feature='excellent', weight=0.016358678622832336, std=0.01002994298413975, value=None), FeatureWeight(feature='great', weight=0.016293394851080674, std=0.01004051484188251, value=None), FeatureWeight(feature='room', weight=0.01266806380524782, std=0.005705833383605878, value=None), FeatureWeight(feature='poor', weight=0.011108300062569292, std=0.006555325938343753, value=None), FeatureWeight(feature='dirty', weight=0.009743350157929077, std=0.006773630310773375, value=None), FeatureWeight(feature='comfortable', weight=0.009264555604520126, std=0.005761873212813875, value=None), FeatureWeight(feature='friendly', weight=0.009154955873755609, std=0.006744783617954844, value=None), FeatureWeight(feature='staff', weight=0.008013262010438392, std=0.0025328811409085334, value=None), FeatureWeight(feature='lovely', weight=0.007502809873736523, std=0.005754579180994447, value=None), FeatureWeight(feature='bad', weight=0.007431244003331236, std=0.004200350353223072, value=None), FeatureWeight(feature='location', weight=0.006871987400056759, std=0.001278738413377038, value=None), FeatureWeight(feature='helpful', weight=0.006828051081067361, std=0.004441680867046844, value=None), FeatureWeight(feature='small', weight=0.006816660851635926, std=0.0024983458777879317, value=None), FeatureWeight(feature='hotel', weight=0.006209221187634678, std=0.0018836164194315297, value=None), FeatureWeight(feature='rude', weight=0.006168502853857298, std=0.0034680517952844925, value=None), FeatureWeight(feature='nice', weight=0.006159836018380767, std=0.0021604996652073577, value=None), FeatureWeight(feature='good', weight=0.006136542296168789, std=0.0012654137464850467, value=None), FeatureWeight(feature='breakfast', weight=0.0057826937111548115, std=0.0013253657566591834, value=None)], remaining=10760), decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(rf_baseline, feature_names=all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest was able to do slightly better than Logistic Regression with an accuracy of 0.8031. Let's see if other models are able to perform better than that. Similarly to Logistic Regression, when looking at cross validation, we can see that the model performed similarly in train set and test set with no signs of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:03:21.971744Z",
     "start_time": "2020-12-24T19:03:21.959086Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "nb_base_cv = MultinomialNB(alpha = .01)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "nb_base_cv.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_nb_base_cv = nb_base_cv.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:03:21.991825Z",
     "start_time": "2020-12-24T19:03:21.973957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "nb_cv_accuracy = accuracy_score(y_test, y_nb_base_cv)\n",
    "nb_cv_precision = precision_score(y_test, y_nb_base_cv)\n",
    "nb_cv_recall = recall_score(y_test, y_nb_base_cv)\n",
    "nb_cv_f1 = f1_score(y_test, y_nb_base_cv)\n",
    "\n",
    "metric_dict['Vanilla Naive Bayes CV'] = {'Accuracy': nb_cv_accuracy,\n",
    "                                                'Precision': nb_cv_precision,\n",
    "                                                'Recall': nb_cv_recall,\n",
    "                                                'F1 Score': nb_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:03:22.057279Z",
     "start_time": "2020-12-24T19:03:21.994335Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7811285846438483\n",
      "Precision: 0.7935413642960812\n",
      "Recall: 0.7807925740806855\n",
      "F1 Score: 0.7871153500089977\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.78939254 0.79925994 0.77582485 0.79401788 0.80289944]\n",
      "Min:  0.775825\n",
      "Max:  0.802899\n",
      "Mean:  0.792279\n",
      "Range:  0.027075\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes baseline evaluation\n",
    "evaluation(y_test, y_nb_base_cv)\n",
    "cross_validation(nb_base_cv, X_train_cv, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes didn't perform as well as Logistic Regression and Random Forest. It's a little surprising to me, since it's well known for being one of the best models for NLP. When looking at cross-validation, we can see that the model performed similarly in the train set compared to the test set with a range between the minimum and maximum a little higher than Logistic Regression and Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:04:45.466507Z",
     "start_time": "2020-12-24T19:03:22.060084Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Naive Bayes Model\n",
    "svc = SVC(kernel='linear')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_cv, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc = svc.predict(X_test_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:04:45.490184Z",
     "start_time": "2020-12-24T19:04:45.468747Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_cv_accuracy = accuracy_score(y_test, y_pred_svc)\n",
    "svc_cv_precision = precision_score(y_test, y_pred_svc)\n",
    "svc_cv_recall = recall_score(y_test, y_pred_svc)\n",
    "svc_cv_f1 = f1_score(y_test, y_pred_svc)\n",
    "\n",
    "metric_dict['Vanilla SVC CV'] = {'Accuracy': svc_cv_accuracy,\n",
    "                                  'Precision': svc_cv_precision,\n",
    "                                  'Recall': svc_cv_recall,\n",
    "                                  'F1 Score': svc_cv_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:07:58.754583Z",
     "start_time": "2020-12-24T19:04:45.493167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7839037927844589\n",
      "Precision: 0.7942342342342342\n",
      "Recall: 0.7868618350589075\n",
      "F1 Score: 0.7905308464849354\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.78353377 0.79432624 0.78939254 0.7875424  0.80043183]\n",
      "Min:  0.783534\n",
      "Max:  0.800432\n",
      "Mean:  0.791045\n",
      "Range:  0.016898\n"
     ]
    }
   ],
   "source": [
    "# SVC baseline evaluation\n",
    "evaluation(y_test, y_pred_svc)\n",
    "cross_validation(svc, X_train_cv, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC also didn't perform as well as Logistic Regression and Random Forest. However, it performed better than Naive Bayes. Thus, I believe it has potential to perform better in further iterations. Using cross-validation I was able to see that the model did not overfit in the trai set and performed similarly to the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:07:58.774152Z",
     "start_time": "2020-12-24T19:07:58.757609Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vanilla Random Forest CV</th>\n",
       "      <td>0.803330</td>\n",
       "      <td>0.838659</td>\n",
       "      <td>0.768297</td>\n",
       "      <td>0.801938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy  Precision    Recall  F1 Score\n",
       "Vanilla Random Forest CV         0.803330   0.838659  0.768297  0.801938\n",
       "Vanilla Logisitic Regression CV  0.798150   0.810458  0.796858  0.803600\n",
       "Vanilla SVC CV                   0.783904   0.794234  0.786862  0.790531\n",
       "Vanilla Naive Bayes CV           0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all the models performed quite well for baseline models. The three best models were Random Forest, Logistic Regression, and SVC. Naive Bayes did a good job as well, but it under performed if compared to the other models in the accuracy metric, which is my focus for this project.\n",
    "\n",
    "It is interesting to see that Logistic Regression performed in second place between these baseline models. It tells us that although not usually seen as a powerful model, it holds it's surprises.\n",
    "\n",
    "I run every model with cross-validation with 5 folds and I don't see any signs of overfit or underfit with the train set. All the models performed similarly in the train set as well in the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will see how each of the three best models in the previous section performs when using the TF-IDF vectorizer. Too keep each to read, the evaluations will be at the end of this section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:19:47.335686Z",
     "start_time": "2021-01-04T18:19:45.268604Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lg_tfidf = LogisticRegression()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lg_tfidf.fit(X_train_tfidf, y_train) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lg_base_tfidf = lg_tfidf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:19:47.358467Z",
     "start_time": "2021-01-04T18:19:47.338275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lg_tfidf_accuracy = accuracy_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_precision = precision_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_recall = recall_score(y_test, y_lg_base_tfidf)\n",
    "lg_tfidf_f1 = f1_score(y_test, y_lg_base_tfidf)\n",
    "\n",
    "metric_dict['Vanila Log Reg TF-IDF'] = {'Accuracy': lg_tfidf_accuracy,\n",
    "                                                'Precision': lg_tfidf_precision,\n",
    "                                                'Recall': lg_tfidf_recall,\n",
    "                                                'F1 Score': lg_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T18:20:31.972202Z",
     "start_time": "2021-01-04T18:19:47.361421Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8170212765957446\n",
      "Precision: 0.8481936971560338\n",
      "Recall: 0.7879328811138879\n",
      "F1 Score: 0.8169535443272257\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.81776133 0.82269504 0.81591119 0.82146161 0.82973473]\n",
      "Min:  0.815911\n",
      "Max:  0.829735\n",
      "Mean:  0.821513\n",
      "Range:  0.013824\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_lg_base_tfidf)\n",
    "cross_validation(lg_tfidf, X_train_tfidf, y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T20:41:00.393881Z",
     "start_time": "2021-01-04T20:41:00.389133Z"
    }
   },
   "outputs": [],
   "source": [
    "all_features = X_train_tfidf.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-04T19:54:53.704117Z",
     "start_time": "2021-01-04T19:54:53.684562Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +6.092\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        excellent\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 81.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.270\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        great\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.38%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.082\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        amazing\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 82.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +5.010\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        comfortable\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 83.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.544\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        lovely\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.222\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bit\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 84.71%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +4.150\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        perfect\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.823\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        spacious\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 85.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.818\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        loved\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.596\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        friendly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.68%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.407\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        wonderful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +3.221\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fantastic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.93%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.963\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        quiet\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.935\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        brilliant\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.896\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        superb\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.73%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.685\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        nice\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.674\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        negative\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 88.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.610\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        come\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.560\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        beautiful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.33%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.482\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        modern\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.424\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        helpful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.99%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.266\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        little\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.235\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        large\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.234\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        fabulous\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.09%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 4592 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.70%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 6139 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.70%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.040\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dusty\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.064\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        attitude\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.62%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.066\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        run\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.58%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.077\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        work\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.118\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        tiny\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.41%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.133\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dated\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.211\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        management\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.09%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.234\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        broken\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.04%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.252\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        charged\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.50%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.428\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        unfriendly\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 89.11%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.556\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        awful\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.89%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.631\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        overpriced\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.699\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        paid\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.46%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.776\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        money\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.801\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        horrible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.830\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        star\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.27%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.843\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        uncomfortable\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 88.20%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.865\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        basic\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.52%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.105\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        bad\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.24%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.208\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        old\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.17%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.230\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        tired\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 87.12%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.248\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        worst\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.451\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        poor\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 86.31%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.543\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        terrible\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 84.39%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -4.277\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        rude\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -5.308\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        dirty\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator='LogisticRegression()', description=\"\\nFeatures with largest coefficients.\\nCaveats:\\n1. Be careful with features which are not\\n   independent - weights don't show their importance.\\n2. If scale of input features is different then scale of coefficients\\n   will also be different, making direct comparison between coefficient values\\n   incorrect.\\n3. Depending on regularization, rare features sometimes may have high\\n   coefficients; this doesn't mean they contribute much to the\\n   classification result for most examples.\\n\", error=None, method='linear model', is_regression=False, targets=[TargetExplanation(target=1, feature_weights=FeatureWeights(pos=[FeatureWeight(feature='excellent', weight=6.092407815822656, std=None, value=None), FeatureWeight(feature='great', weight=5.27019513234399, std=None, value=None), FeatureWeight(feature='amazing', weight=5.0819905911646694, std=None, value=None), FeatureWeight(feature='comfortable', weight=5.00980012556402, std=None, value=None), FeatureWeight(feature='lovely', weight=4.5439398921096466, std=None, value=None), FeatureWeight(feature='bit', weight=4.222406619574978, std=None, value=None), FeatureWeight(feature='perfect', weight=4.150460373249136, std=None, value=None), FeatureWeight(feature='spacious', weight=3.823115533072874, std=None, value=None), FeatureWeight(feature='loved', weight=3.8184576065444293, std=None, value=None), FeatureWeight(feature='friendly', weight=3.595750817062964, std=None, value=None), FeatureWeight(feature='wonderful', weight=3.407176648336035, std=None, value=None), FeatureWeight(feature='fantastic', weight=3.2211391600526422, std=None, value=None), FeatureWeight(feature='quiet', weight=2.9627536500147675, std=None, value=None), FeatureWeight(feature='brilliant', weight=2.9350738487411694, std=None, value=None), FeatureWeight(feature='superb', weight=2.8961085366315107, std=None, value=None), FeatureWeight(feature='nice', weight=2.684675715731104, std=None, value=None), FeatureWeight(feature='negative', weight=2.6744216623977657, std=None, value=None), FeatureWeight(feature='come', weight=2.609931368401085, std=None, value=None), FeatureWeight(feature='beautiful', weight=2.55990437842863, std=None, value=None), FeatureWeight(feature='modern', weight=2.482068260475267, std=None, value=None), FeatureWeight(feature='helpful', weight=2.4242329973885677, std=None, value=None), FeatureWeight(feature='little', weight=2.26640331738448, std=None, value=None), FeatureWeight(feature='large', weight=2.2350838828347452, std=None, value=None), FeatureWeight(feature='fabulous', weight=2.2336391674777496, std=None, value=None)], neg=[FeatureWeight(feature='dirty', weight=-5.308223724900761, std=None, value=None), FeatureWeight(feature='rude', weight=-4.277392964949601, std=None, value=None), FeatureWeight(feature='terrible', weight=-3.5434952063796383, std=None, value=None), FeatureWeight(feature='poor', weight=-3.4512390723038857, std=None, value=None), FeatureWeight(feature='worst', weight=-3.2482320612736544, std=None, value=None), FeatureWeight(feature='tired', weight=-3.2300761106281684, std=None, value=None), FeatureWeight(feature='old', weight=-3.20773710218206, std=None, value=None), FeatureWeight(feature='bad', weight=-3.1048947924899304, std=None, value=None), FeatureWeight(feature='basic', weight=-2.865366759567759, std=None, value=None), FeatureWeight(feature='uncomfortable', weight=-2.8426780366899678, std=None, value=None), FeatureWeight(feature='star', weight=-2.8302088587075205, std=None, value=None), FeatureWeight(feature='horrible', weight=-2.801417396933908, std=None, value=None), FeatureWeight(feature='money', weight=-2.776421436862209, std=None, value=None), FeatureWeight(feature='paid', weight=-2.6992303290348794, std=None, value=None), FeatureWeight(feature='overpriced', weight=-2.631227638929582, std=None, value=None), FeatureWeight(feature='awful', weight=-2.5557129276965123, std=None, value=None), FeatureWeight(feature='unfriendly', weight=-2.4282294025946416, std=None, value=None), FeatureWeight(feature='charged', weight=-2.251946176611073, std=None, value=None), FeatureWeight(feature='broken', weight=-2.234425968408633, std=None, value=None), FeatureWeight(feature='management', weight=-2.211411203463536, std=None, value=None), FeatureWeight(feature='dated', weight=-2.1333975630877644, std=None, value=None), FeatureWeight(feature='tiny', weight=-2.1178239538446855, std=None, value=None), FeatureWeight(feature='work', weight=-2.0770298161789276, std=None, value=None), FeatureWeight(feature='run', weight=-2.0659051168945672, std=None, value=None), FeatureWeight(feature='attitude', weight=-2.063739701983411, std=None, value=None), FeatureWeight(feature='dusty', weight=-2.039884455450589, std=None, value=None)], pos_remaining=4592, neg_remaining=6139), proba=None, score=None, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights(lg_tfidf, feature_names=all_features, top=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an improvement with Logistic Regressing and TF-IDF. The accuracy improved from 0.7981 to 0.8170. We can see that the model performed similarly in every fold when we use cross-validation. As the previous model, there is no underfitting or overfitting in the train set and it performs very similarly to test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:09:10.529877Z",
     "start_time": "2020-12-24T19:08:49.768405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "rf_baseline = RandomForestClassifier()\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_base_tfidf = rf_baseline.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:09:10.547757Z",
     "start_time": "2020-12-24T19:09:10.531952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_tfidf_accuracy = accuracy_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_precision = precision_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_recall = recall_score(y_test, y_rf_base_tfidf)\n",
    "rf_tfidf_f1 = f1_score(y_test, y_rf_base_tfidf)\n",
    "\n",
    "metric_dict['Vanilla Random Forest TF-IDF'] = {'Accuracy': rf_tfidf_accuracy,\n",
    "                                                'Precision': rf_tfidf_precision,\n",
    "                                                'Recall': rf_tfidf_recall,\n",
    "                                                'F1 Score': rf_tfidf_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:49.298852Z",
     "start_time": "2020-12-24T19:09:10.549918Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8061054579093432\n",
      "Precision: 0.8485089463220676\n",
      "Recall: 0.7618707604426991\n",
      "F1 Score: 0.8028592927012792\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.79648474 0.80357693 0.79802652 0.8115942  0.81061073]\n",
      "Min:  0.796485\n",
      "Max:  0.811594\n",
      "Mean:  0.804059\n",
      "Range:  0.015109\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test, y_rf_base_tfidf)\n",
    "cross_validation(rf_baseline, X_train_tfidf, y_train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with TF-IDF also performed slightly better than when I tried it with Count Vectorizer. For now, it seems that TF-IDF works better as a vectorizer for this dataset. Looking at cross-validation, the train set performed similarly with the test set as it happened to previous models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:15:41.667828Z",
     "start_time": "2020-12-24T19:15:41.654130Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vanila Log Reg TF-IDF</th>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.848194</td>\n",
       "      <td>0.787933</td>\n",
       "      <td>0.816954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Random Forest TF-IDF</th>\n",
       "      <td>0.806105</td>\n",
       "      <td>0.848509</td>\n",
       "      <td>0.761871</td>\n",
       "      <td>0.802859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Random Forest CV</th>\n",
       "      <td>0.803330</td>\n",
       "      <td>0.838659</td>\n",
       "      <td>0.768297</td>\n",
       "      <td>0.801938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Logisitic Regression CV</th>\n",
       "      <td>0.798150</td>\n",
       "      <td>0.810458</td>\n",
       "      <td>0.796858</td>\n",
       "      <td>0.803600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla SVC CV</th>\n",
       "      <td>0.783904</td>\n",
       "      <td>0.794234</td>\n",
       "      <td>0.786862</td>\n",
       "      <td>0.790531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vanilla Naive Bayes CV</th>\n",
       "      <td>0.781129</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.780793</td>\n",
       "      <td>0.787115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Accuracy  Precision    Recall  F1 Score\n",
       "Vanila Log Reg TF-IDF            0.817021   0.848194  0.787933  0.816954\n",
       "Vanilla Random Forest TF-IDF     0.806105   0.848509  0.761871  0.802859\n",
       "Vanilla Random Forest CV         0.803330   0.838659  0.768297  0.801938\n",
       "Vanilla Logisitic Regression CV  0.798150   0.810458  0.796858  0.803600\n",
       "Vanilla SVC CV                   0.783904   0.794234  0.786862  0.790531\n",
       "Vanilla Naive Bayes CV           0.781129   0.793541  0.780793  0.787115"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.to_csv('../csv/baseline-models_tfidf.csv')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that all the models using TF-IDF had a better performance than the models using CountVectorizer. SVC model had an big improvement compared to other models and Logistic Regression was able to perform better than Random Forest, which is surprising. The model that had the lowest improvement was Random Forest, which we can see that it changed very little.\n",
    "\n",
    "I will now test these three models with the lemmatized dataset and see if there is any improvement.\n",
    "\n",
    "I used cross-validation in the train set and none of the iterations had underfitting or overfitting. All the models had similar performance in both sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF With Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will try the three best models using the lemmatized variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:15:59.873060Z",
     "start_time": "2020-12-24T19:15:59.454392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Logistic Regression Model\n",
    "lr_lem = LogisticRegression(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "lr_lem.fit(X_train_lem, y_train_lem) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_lr_base_tfidf_lem = lr_lem.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:16:01.670493Z",
     "start_time": "2020-12-24T19:16:01.653957Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "lr_lem_accuracy = accuracy_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_precision = precision_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_recall = recall_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "lr_lem_f1 = f1_score(y_test_lem, y_lr_base_tfidf_lem)\n",
    "\n",
    "metric_dict['Vanilla Log Reg Lem'] = {'Accuracy': lr_lem_accuracy,\n",
    "                                                'Precision': lr_lem_precision,\n",
    "                                                'Recall': lr_lem_recall,\n",
    "                                                'F1 Score': lr_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:16:04.466980Z",
     "start_time": "2020-12-24T19:16:03.487459Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8177613320999075\n",
      "Precision: 0.8314990512333966\n",
      "Recall: 0.8019765739385066\n",
      "F1 Score: 0.8164710266443078\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.82485353 0.82732038 0.82331175 0.80511872 0.8127699 ]\n",
      "Min:  0.805119\n",
      "Max:  0.82732\n",
      "Mean:  0.818675\n",
      "Range:  0.022202\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_lr_base_tfidf_lem)\n",
    "cross_validation(lr_lem, X_train_lem, y_train_lem, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This iteration performed slightly better than the iteration without lemmatization: 0.81777 vs 0.81770. It's a very insignificant improvement. However, we can see that the F1 Score decreased when compared to the model without lemmatization, which is the second metric that I am considering. Looking at cross-validation, both models performed well. However, the model without lemmatization has a lower range in different folds in the train set. Although very small. For now, I consider the model without lemmatization a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:16:29.703455Z",
     "start_time": "2020-12-24T19:16:07.852317Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_lem = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_lem.fit(X_train_lem, y_train_lem) \n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_rf_base_lem = rf_lem.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:16:29.721699Z",
     "start_time": "2020-12-24T19:16:29.705427Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_lem_accuracy = accuracy_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_precision = precision_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_recall = recall_score(y_test_lem, y_rf_base_lem)\n",
    "rf_lem_f1 = f1_score(y_test_lem, y_rf_base_lem)\n",
    "\n",
    "metric_dict['Vanilla Random Forest Lem'] = {'Accuracy': rf_lem_accuracy,\n",
    "                                                'Precision': rf_lem_precision,\n",
    "                                                'Recall': rf_lem_recall,\n",
    "                                                'F1 Score': rf_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:18:14.946200Z",
     "start_time": "2020-12-24T19:16:29.724612Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.7988899167437558\n",
      "Precision: 0.8196657598134474\n",
      "Recall: 0.7719619326500732\n",
      "F1 Score: 0.7950989632422243\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.80881899 0.80296022 0.80296022 0.80357693 0.80074028]\n",
      "Min:  0.80074\n",
      "Max:  0.808819\n",
      "Mean:  0.803811\n",
      "Range:  0.008079\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_rf_base_lem)\n",
    "cross_validation(rf_lem, X_train_lem, y_train_lem, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest with lemmatization did not perform any better than the model without lemmatization. However, it's important to noticed that it had the lowest range of difference between the 5 folds in cross-validation. All sets performed very similarly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:19:58.222650Z",
     "start_time": "2020-12-24T19:18:14.948749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline SVC Model\n",
    "svc = SVC(kernel='rbf')\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "svc.fit(X_train_lem, y_train_lem)\n",
    "\n",
    "# Predicting the model in the X variable of the test set\n",
    "y_pred_svc_lem = svc.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:19:58.277895Z",
     "start_time": "2020-12-24T19:19:58.229143Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_lem_accuracy = accuracy_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_precision = precision_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_recall = recall_score(y_test_lem, y_pred_svc_lem)\n",
    "svc_lem_f1 = f1_score(y_test_lem, y_pred_svc_lem)\n",
    "\n",
    "metric_dict['Vanilla Random Forest Lem'] = {'Accuracy': svc_lem_accuracy,\n",
    "                                                'Precision': svc_lem_precision,\n",
    "                                                'Recall': svc_lem_recall,\n",
    "                                                'F1 Score': svc_lem_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:24:06.987735Z",
     "start_time": "2020-12-24T19:19:58.288721Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.8231267345050879\n",
      "Precision: 0.8493312352478364\n",
      "Recall: 0.7902635431918009\n",
      "F1 Score: 0.8187334091770953\n",
      "\n",
      "Cross-Validation Accuracy Scores: [0.82115325 0.8279371  0.82392846 0.81221092 0.82202344]\n",
      "Min:  0.812211\n",
      "Max:  0.827937\n",
      "Mean:  0.821451\n",
      "Range:  0.015726\n"
     ]
    }
   ],
   "source": [
    "# SCV TF-IDF baseline evaluation\n",
    "evaluation(y_test_lem, y_pred_svc_lem)\n",
    "cross_validation(svc, X_train_lem, y_train_lem, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.279851Z",
     "start_time": "2020-12-24T19:02:25.317Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that Random Forest is our best model so far compared to all the previous model. However, the baseline SVC model using TF-IDF is very close to it with a higher precision and higher F1 Score. They aren't my main focus when it comes to metrics, but I might take in consideration when choosing the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I fixed the class imbalance manually. However, I'm curious to see how my best models will behave using SMOTE. For this reason I'll run two of my best models and see how it would perform with SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.281678Z",
     "start_time": "2020-12-24T19:02:25.323Z"
    }
   },
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_train_smote_lem, y_train_smote_lem = smote.fit_sample(X_train_lem, y_train_lem) \n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote_tfidf, y_train_smote_tfidf = smote.fit_sample(X_train_tfidf, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.283382Z",
     "start_time": "2020-12-24T19:02:25.327Z"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiating baseline Random Forest Model\n",
    "rf_bas eline = RandomForestClassifier(random_state=1)\n",
    "\n",
    "# Fitting the model to the X and y variables of the train set\n",
    "rf_baseline.fit(X_train_smote_lem, y_train_smote_lem)\n",
    "\n",
    "# Predicting the model in the X variable of the test set### Random Forest\n",
    "y_rf_base_lem_tfidf_smote = rf_baseline.predict(X_test_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.284923Z",
     "start_time": "2020-12-24T19:02:25.332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "rf_smote_accuracy = accuracy_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_precision = precision_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_recall = recall_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "rf_smote_f1 = f1_score(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "\n",
    "metric_dict['Vanilla Random Forest SMOTE'] = {'Accuracy': rf_smote_accuracy,\n",
    "                                                'Precision': rf_smote_precision,\n",
    "                                                'Recall': rf_smote_recall,\n",
    "                                                'F1 Score': rf_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.286259Z",
     "start_time": "2020-12-24T19:02:25.336Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "evaluation(y_test_lem, y_rf_base_lem_tfidf_smote)\n",
    "cross_validation(rf_baseline, X_train_smote_lem, y_train_smote_lem, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest did not perform any better using SMOTE. Since the class imbalance was manually fixed, I was not expecting much difference. The model performed similarly as in previous iterations and id doesn't see to have overfitting or underfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:40:32.733033Z",
     "start_time": "2020-12-16T19:40:32.730826Z"
    }
   },
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.287841Z",
     "start_time": "2020-12-24T19:02:25.341Z"
    }
   },
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear')\n",
    "svc.fit(X_train_smote_tfidf, y_train_smote_tfidf)\n",
    "y_pred_svc_smote = svc.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.289224Z",
     "start_time": "2020-12-24T19:02:25.345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating dictionary with all metrics\n",
    "svc_smote_accuracy = accuracy_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_precision = precision_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_recall = recall_score(y_test, y_pred_svc_smote)\n",
    "svc_smote_f1 = f1_score(y_test, y_pred_svc_smote)\n",
    "\n",
    "metric_dict['Vanilla SVC SMOTE'] = {'Accuracy': svc_smote_accuracy,\n",
    "                                                'Precision': svc_smote_precision,\n",
    "                                                'Recall': svc_smote_recall,\n",
    "                                                'F1 Score': svc_smote_f1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.290808Z",
     "start_time": "2020-12-24T19:02:25.350Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "evaluation(y_test, y_pred_svc_smote)\n",
    "cross_validation(svc, X_train_smote_lem, y_train_smote_lem, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please check complete evaluation of all the models below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.292638Z",
     "start_time": "2020-12-24T19:02:25.354Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the SMOTE was able to improve the accuracy metric by a very small different. However, Recall and F1 Score dropped, which tells me that the model is not as good as the version without SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T19:47:12.077415Z",
     "start_time": "2020-12-16T19:47:12.075016Z"
    }
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.294545Z",
     "start_time": "2020-12-24T19:02:25.359Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Evaluation DataFrame\n",
    "evaluation_df = pd.DataFrame.from_dict(metric_dict, orient='index')\n",
    "evaluation_df.to_csv('../csv/baseline-models_evaluations.csv')\n",
    "evaluation_df.sort_values(by='Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running multiple baseline models, we were able to verify a few points:\n",
    "- Our best model was a Random Forest using lemmatized words. However, the F1 score was lower than other models. Since I will focus on F1 Score further in this project, the winner was SVC using TF-IDF. \n",
    "- Random Forest, CVC, and Logistic Regression are the best models to use in NLP in these cases\n",
    "- TF-IDF was able improve all all our models.\n",
    "- Naive Bayes was our worst model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.295940Z",
     "start_time": "2020-12-24T19:02:25.363Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.figure(figsize=(16,6))\n",
    "evaluation_df['Accuracy'].sort_values(ascending=False).plot.bar()\n",
    "plt.xticks(rotation=75, fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.297596Z",
     "start_time": "2020-12-24T19:02:25.368Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plotting a confusion matrix\n",
    "plt.figure(figsize=(6, 7))\n",
    "mat = confusion_matrix(y_test, y_pred_svc_tfidf)\n",
    "\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "            xticklabels=['Positive', 'Negative'], yticklabels=['Positive', 'Negative'], cmap=\"Blues\")\n",
    "plt.xlabel('True Label', fontsize= 18)\n",
    "plt.ylabel('Predicted Label', fontsize= 18)\n",
    "plt.title('Baseline SVC TF-IDF Confusion Matrix', fontsize=20)\n",
    "plt.xticks(fontsize=16)\n",
    "plt.yticks(fontsize=16)\n",
    "b, t = plt.ylim() \n",
    "t -= 0.05 \n",
    "plt.ylim(b, t) \n",
    "plt.savefig('../images/confusion-matrix-baseline-model.png', bbox_inches = \"tight\", pad_inches=.5, dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that my model was able to predict correctly 84.47% of the positive reviews and 72.10% of the negative reviews. This means that I need to improve my model's ability to better predict negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, with my best models in mind, I will run a few ensemble models in the <a href=\"https://github.com/Ismaeltrevi/hotel-reviews-analysis-using-nlp/blob/main/models/ensemble-models.ipynb\">Data Cleaning</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickling files for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.299110Z",
     "start_time": "2020-12-24T19:02:25.373Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/lg_tfidf.pkl\",'wb')\n",
    "pickle.dump(lg_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.300841Z",
     "start_time": "2020-12-24T19:02:25.377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/vanilla_model_evaluation.pkl\",'wb')\n",
    "pickle.dump(evaluation_df, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.302215Z",
     "start_time": "2020-12-24T19:02:25.381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_train_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.303614Z",
     "start_time": "2020-12-24T19:02:25.384Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_tfidf.pkl\",'wb')\n",
    "pickle.dump(X_test_tfidf, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.305154Z",
     "start_time": "2020-12-24T19:02:25.388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train and Test Set  Target\n",
    "y_train.to_pickle(\"../pickle/y_train.pkl\")\n",
    "y_test.to_pickle(\"../pickle/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.306569Z",
     "start_time": "2020-12-24T19:02:25.392Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_cv.pkl\",'wb')\n",
    "pickle.dump(X_train_cv, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.308318Z",
     "start_time": "2020-12-24T19:02:25.396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_cv.pkl\",'wb')\n",
    "pickle.dump(X_test_cv, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.310083Z",
     "start_time": "2020-12-24T19:02:25.400Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/rf_lem_model.pkl\",'wb')\n",
    "pickle.dump(rf_lem, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.311979Z",
     "start_time": "2020-12-24T19:02:25.404Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train Set - Features\n",
    "pickle_out = open(\"../pickle/X_train_lem.pkl\",'wb')\n",
    "pickle.dump(X_train_lem, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.313498Z",
     "start_time": "2020-12-24T19:02:25.408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Test Set - Features\n",
    "pickle_out = open(\"../pickle/X_test_lem.pkl\",'wb')\n",
    "pickle.dump(X_test_lem, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.315002Z",
     "start_time": "2020-12-24T19:02:25.412Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickling Train and Test Set - Target\n",
    "y_train_lem.to_pickle(\"../pickle/y_train_lem.pkl\")\n",
    "y_test_lem.to_pickle(\"../pickle/y_test_lem.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-24T19:11:50.316505Z",
     "start_time": "2020-12-24T19:02:25.416Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pickle best model using CountVectorizer\n",
    "pickle_out = open(\"../pickle/lg_cv.pickle\",\"wb\")\n",
    "pickle.dump(lg_cv, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.390625px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
